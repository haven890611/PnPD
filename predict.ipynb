{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/P111yhchen/anaconda3/envs/yolov13/lib/python3.11/site-packages/albumentations/__init__.py:28: UserWarning: A new version of Albumentations is available: '2.0.8' (you have '2.0.4'). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "from albumentations.augmentations import transforms\n",
    "from albumentations.core.composition import Compose, OneOf\n",
    "from albumentations import RandomRotate90,Resize\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image / label root\n",
    "image_root = \"/local_data/dataset/polyp/detection/patients_complete/images/val/\"\n",
    "label_root = \"/local_data/dataset/polyp/detection/patients_complete/labels/val/\"\n",
    "\n",
    "# ---------------------- config ----------------------\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "NUM_CLASSES_DET = 2     # hyperplastic, adenoma\n",
    "BG_INDEX_SEG = 2        # segmentation 的背景 channel index\n",
    "IOU_THRESH_EVAL = 0.5   # mAP50\n",
    "CONF_THRESH_DET = 0.001 # 要求的 detection conf 門檻"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#images in val: 704\n"
     ]
    }
   ],
   "source": [
    "# ---------------------- main loop ----------------------\n",
    "img_exts = (\"*.jpg\", \"*.jpeg\", \"*.png\", \"*.bmp\", \"*.tif\")\n",
    "img_paths = []\n",
    "for e in img_exts:\n",
    "    img_paths.extend(glob.glob(os.path.join(image_root, e)))\n",
    "img_paths = sorted(img_paths)\n",
    "\n",
    "print(f\"#images in val: {len(img_paths)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------- helpers ----------------------\n",
    "def load_yolo_gt(label_path, img_w, img_h, num_classes=NUM_CLASSES_DET):\n",
    "    \"\"\"\n",
    "    讀取 YOLO txt labels -> list of {cls, box=[x1,y1,x2,y2]}\n",
    "    \"\"\"\n",
    "    if not os.path.exists(label_path):\n",
    "        return {c: [] for c in range(num_classes)}\n",
    "\n",
    "    with open(label_path, \"r\") as f:\n",
    "        lines = [x.strip() for x in f.readlines() if x.strip()]\n",
    "\n",
    "    gts_per_cls = {c: [] for c in range(num_classes)}\n",
    "    if not lines:\n",
    "        return gts_per_cls\n",
    "\n",
    "    for line in lines:\n",
    "        parts = line.split()\n",
    "        if len(parts) != 5:\n",
    "            continue\n",
    "        cls = int(float(parts[0]))\n",
    "        if cls >= num_classes:\n",
    "            continue\n",
    "        xc, yc, w, h = map(float, parts[1:])\n",
    "        xc *= img_w\n",
    "        yc *= img_h\n",
    "        w *= img_w\n",
    "        h *= img_h\n",
    "        x1 = xc - w / 2\n",
    "        y1 = yc - h / 2\n",
    "        x2 = xc + w / 2\n",
    "        y2 = yc + h / 2\n",
    "        gts_per_cls[cls].append([x1, y1, x2, y2])\n",
    "\n",
    "    return gts_per_cls\n",
    "    \n",
    "def box_iou_np(box1, box2):\n",
    "    \"\"\"\n",
    "    box1: (N,4), box2:(M,4) in xyxy\n",
    "    return IoU: (N,M)\n",
    "    \"\"\"\n",
    "    if box1.size == 0 or box2.size == 0:\n",
    "        return np.zeros((box1.shape[0], box2.shape[0]))\n",
    "\n",
    "    box1 = box1.astype(np.float32)\n",
    "    box2 = box2.astype(np.float32)\n",
    "\n",
    "    area1 = np.clip(box1[:, 2] - box1[:, 0], 0, None) * np.clip(box1[:, 3] - box1[:, 1], 0, None)\n",
    "    area2 = np.clip(box2[:, 2] - box2[:, 0], 0, None) * np.clip(box2[:, 3] - box2[:, 1], 0, None)\n",
    "\n",
    "    inter_x1 = np.maximum(box1[:, None, 0], box2[None, :, 0])\n",
    "    inter_y1 = np.maximum(box1[:, None, 1], box2[None, :, 1])\n",
    "    inter_x2 = np.minimum(box1[:, None, 2], box2[None, :, 2])\n",
    "    inter_y2 = np.minimum(box1[:, None, 3], box2[None, :, 3])\n",
    "\n",
    "    inter_w = np.clip(inter_x2 - inter_x1, 0, None)\n",
    "    inter_h = np.clip(inter_y2 - inter_y1, 0, None)\n",
    "    inter = inter_w * inter_h\n",
    "\n",
    "    union = area1[:, None] + area2[None, :] - inter + 1e-16\n",
    "    return inter / union\n",
    "\n",
    "def compute_confusion_matrix(predictions,\n",
    "                             gt_boxes_per_image,\n",
    "                             num_classes=2,\n",
    "                             conf_th=0.25,\n",
    "                             iou_th=0.5):\n",
    "    \"\"\"\n",
    "    Return confusion matrix of shape (num_classes+1, num_classes+1)\n",
    "    rows:    predicted class (最後一列 = predicted background)\n",
    "    columns: ground-truth class (最後一欄 = GT background)\n",
    "    \"\"\"\n",
    "    bg = num_classes\n",
    "    cm = np.zeros((num_classes + 1, num_classes + 1), dtype=np.int64)\n",
    "\n",
    "    # 先把 prediction 按 image_id group 起來比較快\n",
    "    preds_by_img = {}\n",
    "    for p in predictions:\n",
    "        if p[\"score\"] < conf_th:\n",
    "            continue\n",
    "        preds_by_img.setdefault(p[\"image_id\"], []).append(p)\n",
    "\n",
    "    for img_id, gt_dict in gt_boxes_per_image.items():\n",
    "        # collect all GT boxes for this image\n",
    "        gt_boxes = []\n",
    "        gt_cls = []\n",
    "        for c in range(num_classes):\n",
    "            for b in gt_dict[c]:\n",
    "                gt_boxes.append(b)\n",
    "                gt_cls.append(c)\n",
    "        gt_boxes = np.array(gt_boxes, dtype=np.float32)\n",
    "        gt_cls = np.array(gt_cls, dtype=np.int64)\n",
    "\n",
    "        preds = preds_by_img.get(img_id, [])\n",
    "        if len(preds) == 0 and gt_boxes.size == 0:\n",
    "            continue\n",
    "\n",
    "        pred_boxes = np.array([p[\"box\"] for p in preds], dtype=np.float32) if preds else np.zeros((0, 4), dtype=np.float32)\n",
    "        pred_cls = np.array([p[\"cls\"] for p in preds], dtype=np.int64) if preds else np.zeros((0,), dtype=np.int64)\n",
    "\n",
    "        N, M = pred_boxes.shape[0], gt_boxes.shape[0]\n",
    "\n",
    "        if N > 0 and M > 0:\n",
    "            ious = box_iou_np(pred_boxes, gt_boxes)  # (N,M)\n",
    "            matched_pred = np.zeros(N, dtype=bool)\n",
    "            matched_gt = np.zeros(M, dtype=bool)\n",
    "\n",
    "            # greedy 1-1 matching by IoU\n",
    "            while True:\n",
    "                idx = np.unravel_index(np.argmax(ious), ious.shape)\n",
    "                max_iou = ious[idx]\n",
    "                if max_iou < iou_th:\n",
    "                    break\n",
    "                pi, gj = idx\n",
    "                if matched_pred[pi] or matched_gt[gj]:\n",
    "                    ious[pi, gj] = -1.0\n",
    "                    continue\n",
    "                matched_pred[pi] = True\n",
    "                matched_gt[gj] = True\n",
    "\n",
    "                pc = int(pred_cls[pi])\n",
    "                gc = int(gt_cls[gj])\n",
    "                cm[pc, gc] += 1\n",
    "\n",
    "                ious[pi, :] = -1.0\n",
    "                ious[:, gj] = -1.0\n",
    "\n",
    "            # unmatched predictions -> predicted some class, GT background\n",
    "            for i in range(N):\n",
    "                if not matched_pred[i]:\n",
    "                    pc = int(pred_cls[i])\n",
    "                    cm[pc, bg] += 1\n",
    "\n",
    "            # unmatched GT -> predicted background, GT some class\n",
    "            for j in range(M):\n",
    "                if not matched_gt[j]:\n",
    "                    gc = int(gt_cls[j])\n",
    "                    cm[bg, gc] += 1\n",
    "\n",
    "        elif N > 0 and M == 0:\n",
    "            # all preds are FP, GT background\n",
    "            for pc in pred_cls:\n",
    "                cm[int(pc), bg] += 1\n",
    "        elif N == 0 and M > 0:\n",
    "            # all GT are FN, predicted background\n",
    "            for gc in gt_cls:\n",
    "                cm[bg, int(gc)] += 1\n",
    "\n",
    "    return cm\n",
    "\n",
    "# -------------------  Detection Metrics (AP) ------------------------------\n",
    "def prepare_gt_class_agnostic(gt_boxes_per_image):\n",
    "    gt_nocls = {}\n",
    "    for img_id, v in gt_boxes_per_image.items():\n",
    "        boxes = []\n",
    "        if isinstance(v, dict):\n",
    "            # v: {cls: [[...], ...], ...}\n",
    "            for cls, box_list in v.items():\n",
    "                if box_list is None:\n",
    "                    continue\n",
    "                for b in box_list:\n",
    "                    boxes.append(b)\n",
    "        else:\n",
    "            # 若本來就已經是 list of boxes\n",
    "            boxes = v\n",
    "\n",
    "        if len(boxes) > 0:\n",
    "            gt_nocls[img_id] = np.asarray(boxes, dtype=np.float32).reshape(-1, 4)\n",
    "        else:\n",
    "            gt_nocls[img_id] = np.zeros((0, 4), dtype=np.float32)\n",
    "    return gt_nocls\n",
    "\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 單一 box 對多個 boxes 的 IoU\n",
    "# box: shape (4,), boxes: shape (N, 4)\n",
    "# -------------------------------------------------\n",
    "def box_iou(box, boxes):\n",
    "    if boxes.size == 0:\n",
    "        return np.zeros((0,), dtype=np.float32)\n",
    "\n",
    "    x1 = np.maximum(box[0], boxes[:, 0])\n",
    "    y1 = np.maximum(box[1], boxes[:, 1])\n",
    "    x2 = np.minimum(box[2], boxes[:, 2])\n",
    "    y2 = np.minimum(box[3], boxes[:, 3])\n",
    "\n",
    "    inter_w = np.clip(x2 - x1, a_min=0, a_max=None)\n",
    "    inter_h = np.clip(y2 - y1, a_min=0, a_max=None)\n",
    "    inter = inter_w * inter_h\n",
    "\n",
    "    area_box = (box[2] - box[0]) * (box[3] - box[1])\n",
    "    area_boxes = (boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 1])\n",
    "\n",
    "    union = area_box + area_boxes - inter\n",
    "    iou = np.where(union > 0, inter / union, 0.0)\n",
    "    return iou\n",
    "\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 計算「不分分類」的 AP@iou_thr\n",
    "# all_predictions: list of dict\n",
    "#   {\"image_id\": str, \"cls\": int, \"score\": float, \"box\": [x1,y1,x2,y2]}\n",
    "# gt_boxes_per_image: img_id -> {cls: [[x1,y1,x2,y2], ...]}\n",
    "# -------------------------------------------------\n",
    "def compute_ap_class_agnostic(all_predictions, gt_boxes_per_image, iou_thr=0.5):\n",
    "    \"\"\"\n",
    "    class-agnostic 的 AP 計算：\n",
    "    - 忽略 pred[\"cls\"]，只看 image_id / box / score。\n",
    "    - 回傳 AP + 原始 PR curve + COCO 插值後 PR + 對應的 score threshold。\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    ap : float\n",
    "        指定 IoU 門檻下的 Average Precision。\n",
    "    recalls : np.ndarray, shape (N,)\n",
    "        依照 score 從高到低加點時，每一點的 recall。\n",
    "    precisions : np.ndarray, shape (N,)\n",
    "        依照 score 從高到低加點時，每一點的 precision。\n",
    "    rec_points : np.ndarray, shape (101,)\n",
    "        COCO 風格的固定 recall 取樣點：0.00, 0.01, ..., 1.00。\n",
    "    prec_interp : np.ndarray, shape (101,)\n",
    "        對應到 rec_points 的「插值後」precision（用來算 AP 的 PR 曲線）。\n",
    "    thresholds : np.ndarray, shape (N,)\n",
    "        每一個 PR 點對應的 score threshold（第 i 個點 = 保留 score ≥ thresholds[i]）。\n",
    "    \"\"\"\n",
    "    # 先把 GT 合併成「不分 class」版本\n",
    "    gt_nocls = prepare_gt_class_agnostic(gt_boxes_per_image)\n",
    "\n",
    "    # 總 GT 數量 (所有圖、所有類別加總)\n",
    "    npos = sum(len(b) for b in gt_nocls.values())\n",
    "    if npos == 0:\n",
    "        return float(\"nan\"), None, None, None, None, None\n",
    "\n",
    "    # 依照 score 由大到小排序 (完全忽略 cls)\n",
    "    preds = sorted(all_predictions, key=lambda x: x[\"score\"], reverse=True)\n",
    "\n",
    "    tp = np.zeros(len(preds), dtype=np.float32)\n",
    "    fp = np.zeros(len(preds), dtype=np.float32)\n",
    "    thresholds = np.array([p[\"score\"] for p in preds], dtype=np.float32)\n",
    "\n",
    "    # 每張圖的每個 GT 只能被 match 一次\n",
    "    gt_used = {img_id: np.zeros(len(boxes), dtype=bool)\n",
    "               for img_id, boxes in gt_nocls.items()}\n",
    "\n",
    "    for i, p in enumerate(preds):\n",
    "        img_id = p[\"image_id\"]\n",
    "        box = np.asarray(p[\"box\"], dtype=np.float32)\n",
    "\n",
    "        gt_boxes = gt_nocls.get(img_id, None)\n",
    "        if gt_boxes is None or len(gt_boxes) == 0:\n",
    "            # 這張圖沒有 GT，任何預測都是 FP\n",
    "            fp[i] = 1.0\n",
    "            continue\n",
    "\n",
    "        ious = box_iou(box, gt_boxes)\n",
    "        max_iou_idx = int(np.argmax(ious))\n",
    "        max_iou = float(ious[max_iou_idx])\n",
    "\n",
    "        if max_iou >= iou_thr and not gt_used[img_id][max_iou_idx]:\n",
    "            tp[i] = 1.0\n",
    "            gt_used[img_id][max_iou_idx] = True\n",
    "        else:\n",
    "            fp[i] = 1.0\n",
    "\n",
    "    # ------- 原始 PR curve（每加一個預測點更新一次） -------\n",
    "    tp_cum = np.cumsum(tp)\n",
    "    fp_cum = np.cumsum(fp)\n",
    "\n",
    "    recalls = tp_cum / npos\n",
    "    precisions = tp_cum / np.maximum(tp_cum + fp_cum, 1e-8)\n",
    "\n",
    "    # ------- COCO 風格：在 0~1 的 101 個 recall 點做插值 -------\n",
    "    rec_points = np.linspace(0.0, 1.0, 101)\n",
    "    prec_interp = np.zeros_like(rec_points)\n",
    "\n",
    "    for idx, r in enumerate(rec_points):\n",
    "        # 找到所有 recall >= r 的點，取其中最大的 precision\n",
    "        mask = recalls >= r\n",
    "        if np.any(mask):\n",
    "            prec_interp[idx] = np.max(precisions[mask])\n",
    "        else:\n",
    "            prec_interp[idx] = 0.0\n",
    "\n",
    "    ap = float(np.mean(prec_interp))\n",
    "\n",
    "    return ap, recalls, precisions, rec_points, prec_interp, thresholds\n",
    "\n",
    "def find_best_f1_threshold(precisions, recalls, thresholds):\n",
    "    \"\"\"\n",
    "    根據原始 PR curve 的每個點計算 F1，找出 F1 最大的點。\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    best_thresh : float\n",
    "        讓 F1 最大的 confidence threshold（score）。\n",
    "    best_f1 : float\n",
    "        最大的 F1 值。\n",
    "    best_p : float\n",
    "        該 threshold 底下的 precision。\n",
    "    best_r : float\n",
    "        該 threshold 底下的 recall。\n",
    "    \"\"\"\n",
    "    # F1 = 2PR / (P+R)\n",
    "    denom = precisions + recalls\n",
    "    f1 = np.where(denom > 0, 2 * precisions * recalls / denom, 0.0)\n",
    "\n",
    "    if len(f1) == 0:\n",
    "        return None, None, None, None\n",
    "\n",
    "    best_idx = int(np.argmax(f1))\n",
    "    best_thresh = float(thresholds[best_idx])\n",
    "    best_f1 = float(f1[best_idx])\n",
    "    best_p = float(precisions[best_idx])\n",
    "    best_r = float(recalls[best_idx])\n",
    "    return best_thresh, best_f1, best_p, best_r\n",
    "    \n",
    "\n",
    "# -------------------------------------------------\n",
    "# 實際計算 AP@50, AP@75, AP@50:95\n",
    "# all_predictions / gt_boxes_per_image 用你 main loop 算好的那兩個變數\n",
    "# -------------------------------------------------\n",
    "# AP@50:95\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yolov11l\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating dual-path: 100%|██████████| 704/704 [00:51<00:00, 13.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion matrix @50 (rows=pred, cols=gt, last index = background):\n",
      "[[191  88  88]\n",
      " [ 81 252  93]\n",
      " [ 51  71   0]]\n",
      "[class 0] precision: 0.5204  recall: 0.5913 \n",
      "[class 1] precision: 0.5915  recall: 0.6131 \n",
      "AP@50:95: 0.5651\n",
      "[IoU=0.5] best threshold = 0.3104\n",
      "[IoU=0.5] AP = 0.8727\n",
      "[IoU=0.5] precision = 0.8207, recall = 0.8106\n",
      "[IoU=0.5] best F1 = 0.8156\n",
      "yolov11x\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating dual-path: 100%|██████████| 704/704 [00:16<00:00, 42.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion matrix @50 (rows=pred, cols=gt, last index = background):\n",
      "[[168  84  58]\n",
      " [ 87 272  71]\n",
      " [ 68  55   0]]\n",
      "[class 0] precision: 0.5419  recall: 0.5201 \n",
      "[class 1] precision: 0.6326  recall: 0.6618 \n",
      "AP@50:95: 0.5696\n",
      "[IoU=0.5] best threshold = 0.4148\n",
      "[IoU=0.5] AP = 0.8870\n",
      "[IoU=0.5] precision = 0.8797, recall = 0.7970\n",
      "[IoU=0.5] best F1 = 0.8363\n",
      "yolov12l\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating dual-path: 100%|██████████| 704/704 [00:22<00:00, 31.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion matrix @50 (rows=pred, cols=gt, last index = background):\n",
      "[[187  74  84]\n",
      " [ 93 276  99]\n",
      " [ 43  61   0]]\n",
      "[class 0] precision: 0.5420  recall: 0.5789 \n",
      "[class 1] precision: 0.5897  recall: 0.6715 \n",
      "AP@50:95: 0.5566\n",
      "[IoU=0.5] best threshold = 0.4495\n",
      "[IoU=0.5] AP = 0.8741\n",
      "[IoU=0.5] precision = 0.8782, recall = 0.7956\n",
      "[IoU=0.5] best F1 = 0.8349\n",
      "yolov12x\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating dual-path: 100%|██████████| 704/704 [00:22<00:00, 31.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion matrix @50 (rows=pred, cols=gt, last index = background):\n",
      "[[186  77  86]\n",
      " [ 86 275 100]\n",
      " [ 51  59   0]]\n",
      "[class 0] precision: 0.5330  recall: 0.5759 \n",
      "[class 1] precision: 0.5965  recall: 0.6691 \n",
      "AP@50:95: 0.5685\n",
      "[IoU=0.5] best threshold = 0.4412\n",
      "[IoU=0.5] AP = 0.8799\n",
      "[IoU=0.5] precision = 0.8737, recall = 0.7916\n",
      "[IoU=0.5] best F1 = 0.8306\n",
      "yolov13l\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating dual-path:  88%|████████▊ | 622/704 [00:25<00:03, 24.07it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 30\u001b[39m\n\u001b[32m     27\u001b[39m all_predictions = []  \u001b[38;5;66;03m# 全部 pred bbox\u001b[39;00m\n\u001b[32m     28\u001b[39m gt_boxes_per_image = {}  \u001b[38;5;66;03m# img_id -> {cls: [[x1,y1,x2,y2], ...]}\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_paths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mEvaluating dual-path\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimg_id\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbasename\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/nfs/P111yhchen/anaconda3/envs/yolov13/lib/python3.11/site-packages/tqdm/std.py:1191\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1189\u001b[39m dt = cur_t - last_print_t\n\u001b[32m   1190\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dt >= mininterval \u001b[38;5;129;01mand\u001b[39;00m cur_t >= min_start_t:\n\u001b[32m-> \u001b[39m\u001b[32m1191\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43mlast_print_n\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1192\u001b[39m     last_print_n = \u001b[38;5;28mself\u001b[39m.last_print_n\n\u001b[32m   1193\u001b[39m     last_print_t = \u001b[38;5;28mself\u001b[39m.last_print_t\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/nfs/P111yhchen/anaconda3/envs/yolov13/lib/python3.11/site-packages/tqdm/std.py:1242\u001b[39m, in \u001b[36mtqdm.update\u001b[39m\u001b[34m(self, n)\u001b[39m\n\u001b[32m   1240\u001b[39m     \u001b[38;5;28mself\u001b[39m._ema_dn(dn)\n\u001b[32m   1241\u001b[39m     \u001b[38;5;28mself\u001b[39m._ema_dt(dt)\n\u001b[32m-> \u001b[39m\u001b[32m1242\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrefresh\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlock_args\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlock_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1243\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dynamic_miniters:\n\u001b[32m   1244\u001b[39m     \u001b[38;5;66;03m# If no `miniters` was specified, adjust automatically to the\u001b[39;00m\n\u001b[32m   1245\u001b[39m     \u001b[38;5;66;03m# maximum iteration rate seen so far between two prints.\u001b[39;00m\n\u001b[32m   1246\u001b[39m     \u001b[38;5;66;03m# e.g.: After running `tqdm.update(5)`, subsequent\u001b[39;00m\n\u001b[32m   1247\u001b[39m     \u001b[38;5;66;03m# calls to `tqdm.update()` will only cause an update after\u001b[39;00m\n\u001b[32m   1248\u001b[39m     \u001b[38;5;66;03m# at least 5 more iterations.\u001b[39;00m\n\u001b[32m   1249\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.maxinterval \u001b[38;5;129;01mand\u001b[39;00m dt >= \u001b[38;5;28mself\u001b[39m.maxinterval:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/nfs/P111yhchen/anaconda3/envs/yolov13/lib/python3.11/site-packages/tqdm/std.py:1347\u001b[39m, in \u001b[36mtqdm.refresh\u001b[39m\u001b[34m(self, nolock, lock_args)\u001b[39m\n\u001b[32m   1345\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1346\u001b[39m         \u001b[38;5;28mself\u001b[39m._lock.acquire()\n\u001b[32m-> \u001b[39m\u001b[32m1347\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdisplay\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1348\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m nolock:\n\u001b[32m   1349\u001b[39m     \u001b[38;5;28mself\u001b[39m._lock.release()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/nfs/P111yhchen/anaconda3/envs/yolov13/lib/python3.11/site-packages/tqdm/std.py:1495\u001b[39m, in \u001b[36mtqdm.display\u001b[39m\u001b[34m(self, msg, pos)\u001b[39m\n\u001b[32m   1493\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pos:\n\u001b[32m   1494\u001b[39m     \u001b[38;5;28mself\u001b[39m.moveto(pos)\n\u001b[32m-> \u001b[39m\u001b[32m1495\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[34;43m__str__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1496\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pos:\n\u001b[32m   1497\u001b[39m     \u001b[38;5;28mself\u001b[39m.moveto(-pos)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/nfs/P111yhchen/anaconda3/envs/yolov13/lib/python3.11/site-packages/tqdm/std.py:459\u001b[39m, in \u001b[36mtqdm.status_printer.<locals>.print_status\u001b[39m\u001b[34m(s)\u001b[39m\n\u001b[32m    457\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mprint_status\u001b[39m(s):\n\u001b[32m    458\u001b[39m     len_s = disp_len(s)\n\u001b[32m--> \u001b[39m\u001b[32m459\u001b[39m     \u001b[43mfp_write\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\r\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m \u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlast_len\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43mlen_s\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    460\u001b[39m     last_len[\u001b[32m0\u001b[39m] = len_s\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/nfs/P111yhchen/anaconda3/envs/yolov13/lib/python3.11/site-packages/tqdm/std.py:452\u001b[39m, in \u001b[36mtqdm.status_printer.<locals>.fp_write\u001b[39m\u001b[34m(s)\u001b[39m\n\u001b[32m    451\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfp_write\u001b[39m(s):\n\u001b[32m--> \u001b[39m\u001b[32m452\u001b[39m     \u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    453\u001b[39m     fp_flush()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/nfs/P111yhchen/anaconda3/envs/yolov13/lib/python3.11/site-packages/tqdm/utils.py:196\u001b[39m, in \u001b[36mDisableOnWriteError.disable_on_exception.<locals>.inner\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    194\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minner\u001b[39m(*args, **kwargs):\n\u001b[32m    195\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    197\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    198\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m e.errno != \u001b[32m5\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/nfs/P111yhchen/anaconda3/envs/yolov13/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3045\u001b[39m, in \u001b[36mInteractiveShell._tee.<locals>.write\u001b[39m\u001b[34m(data, *args, **kwargs)\u001b[39m\n\u001b[32m   3043\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrite\u001b[39m(data, *args, **kwargs):\n\u001b[32m   3044\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Write data to both the original destination and the capture dictionary.\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3045\u001b[39m     result = \u001b[43moriginal_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3046\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[32m   3047\u001b[39m         [\n\u001b[32m   3048\u001b[39m             \u001b[38;5;28mself\u001b[39m.display_pub.is_publishing,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3051\u001b[39m         ]\n\u001b[32m   3052\u001b[39m     ):\n\u001b[32m   3053\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/nfs/P111yhchen/anaconda3/envs/yolov13/lib/python3.11/site-packages/ipykernel/iostream.py:681\u001b[39m, in \u001b[36mOutStream.write\u001b[39m\u001b[34m(self, string)\u001b[39m\n\u001b[32m    678\u001b[39m     msg = \u001b[33m\"\u001b[39m\u001b[33mI/O operation on closed file\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    679\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m681\u001b[39m is_child = \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_is_master_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    682\u001b[39m \u001b[38;5;66;03m# only touch the buffer in the IO thread to avoid races\u001b[39;00m\n\u001b[32m    683\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._buffer_lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/nfs/P111yhchen/anaconda3/envs/yolov13/lib/python3.11/site-packages/ipykernel/iostream.py:550\u001b[39m, in \u001b[36mOutStream._is_master_process\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    547\u001b[39m     \u001b[38;5;28mself\u001b[39m.watch_fd_thread.daemon = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    548\u001b[39m     \u001b[38;5;28mself\u001b[39m.watch_fd_thread.start()\n\u001b[32m--> \u001b[39m\u001b[32m550\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_is_master_process\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    551\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m os.getpid() == \u001b[38;5;28mself\u001b[39m._master_pid\n\u001b[32m    553\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mset_parent\u001b[39m(\u001b[38;5;28mself\u001b[39m, parent):\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "from ultralytics import YOLO\n",
    "# model_dict = {\n",
    "#     'v8':  ['n', 's', 'm'],\n",
    "#     'v9':  ['t', 's', 'm'],\n",
    "#     'v10': ['n', 's', 'm'],\n",
    "#     'v11': ['n', 's', 'm'],\n",
    "#     'v12': ['n', 's', 'm'],\n",
    "#     'v13': ['n', 's'],\n",
    "# }\n",
    "model_dict = {\n",
    "    'v11': ['l', 'x'],\n",
    "    'v12': ['l', 'x'],\n",
    "    'v13': ['l', 'x'],\n",
    "}\n",
    "for k in model_dict.keys():\n",
    "    for s in model_dict[k]:\n",
    "        # detection model (YOLOv13-n)\n",
    "\n",
    "        model_path = f'/nfs/P111yhchen/code/detection/det_branch/{k}/yolo{k}{s}/weights/best.pt'\n",
    "        if not os.path.exists(model_path):\n",
    "            continue\n",
    "        print(f'yolo{k}{s}')\n",
    "        model_det = YOLO(model_path)\n",
    "\n",
    "        all_predictions = []  # 全部 pred bbox\n",
    "        gt_boxes_per_image = {}  # img_id -> {cls: [[x1,y1,x2,y2], ...]}\n",
    "\n",
    "        for img_path in tqdm(img_paths, desc=\"Evaluating dual-path\"):\n",
    "            img_id = os.path.splitext(os.path.basename(img_path))[0]\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is None:\n",
    "                continue\n",
    "            h0, w0 = img.shape[:2]\n",
    "\n",
    "            # ------ GT ------\n",
    "            label_path = os.path.join(label_root, img_id + \".txt\")\n",
    "            gt_boxes_per_image[img_id] = load_yolo_gt(label_path, w0, h0)\n",
    "\n",
    "            # ------ detection (YOLO) ------\n",
    "            # Ultralytics: conf threshold 在這裡設定\n",
    "            results = model_det.predict(\n",
    "                img,  # BGR numpy\n",
    "                single_cls=True,\n",
    "                conf=CONF_THRESH_DET,\n",
    "                iou=0.7,     # NMS 的 IoU 門檻，依需要調\n",
    "                verbose=False,\n",
    "                device=device,\n",
    "            )\n",
    "            \n",
    "            r = results[0]\n",
    "            if r.boxes is None or len(r.boxes) == 0:\n",
    "                continue\n",
    "\n",
    "            boxes = r.boxes.xyxy.cpu().numpy()\n",
    "            scores = r.boxes.conf.cpu().numpy()\n",
    "            clses = r.boxes.cls.cpu().numpy()\n",
    "            for det_cls, box, score in zip(clses, boxes, scores):\n",
    "                all_predictions.append({\n",
    "                    \"image_id\": img_id,\n",
    "                    \"cls\": int(det_cls),\n",
    "                    \"score\": float(score),\n",
    "                    \"box\": box.tolist(),\n",
    "                })\n",
    "\n",
    "        aps = []\n",
    "        thrs = [] # conf_thr with best F1 score\n",
    "        rs = [] \n",
    "        ps = []\n",
    "        for thr in np.arange(0.5, 1.0, 0.05):  # 0.50, 0.55, ..., 0.95\n",
    "            ap_i, r_i, p_i, _, _, thr_i = compute_ap_class_agnostic(\n",
    "                all_predictions, gt_boxes_per_image, iou_thr=thr\n",
    "            )\n",
    "            aps.append(ap_i)\n",
    "            thrs.append(thr_i)\n",
    "            rs.append(r_i)\n",
    "            ps.append(p_i)\n",
    "        ap_50_95 = float(np.mean(aps))\n",
    "        best_thr_50, best_f1_50, best_p_50, best_r_50 = find_best_f1_threshold(ps[0], rs[0], thrs[0])\n",
    "        cm = compute_confusion_matrix(\n",
    "            all_predictions,\n",
    "            gt_boxes_per_image,\n",
    "            num_classes=NUM_CLASSES_DET,\n",
    "            conf_th=0.25,   # 想和 ultralytics 一樣就設 0.25\n",
    "            iou_th=0.5\n",
    "        )\n",
    "        print(\"\\nConfusion matrix @50 (rows=pred, cols=gt, last index = background):\")\n",
    "        print(cm)\n",
    "        for ci in range(NUM_CLASSES_DET):\n",
    "            pp = cm[ci, ci]/cm[ci].sum()\n",
    "            rr = cm[ci, ci]/cm[:, ci].sum()\n",
    "            print(f\"[class {ci}] precision: {pp:.4f}  recall: {rr:.4f} \")\n",
    "\n",
    "        print(f\"AP@50:95: {ap_50_95:.4f}\")\n",
    "\n",
    "        print(f\"[IoU=0.5] best threshold = {best_thr_50:.4f}\")\n",
    "        print(f\"[IoU=0.5] AP = {aps[0]:.4f}\")\n",
    "        print(f\"[IoU=0.5] precision = {best_p_50:.4f}, recall = {best_r_50:.4f}\")\n",
    "        print(f\"[IoU=0.5] best F1 = {best_f1_50:.4f}\")\n",
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
