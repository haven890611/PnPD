{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VIBIBLE_DEVICES']='0'\n",
    "from ultralytics import YOLO\n",
    "\n",
    "import torch\n",
    "import time\n",
    "from thop import profile\n",
    "from thop import clever_format\n",
    "# model_dict = {\n",
    "#     'v8':  ['n', 's', 'm', 'l', 'x'],\n",
    "#     'v9':  ['t', 's', 'm', 'c', 'e'],\n",
    "#     'v10': ['n', 's', 'm', 'b', 'l', 'x'],\n",
    "#     'v11': ['n', 's', 'm', 'l', 'x'],\n",
    "#     'v12': ['n', 's', 'm', 'l', 'x'],\n",
    "#     'v13': ['n', 's', 'l', 'x'],\n",
    "# }\n",
    "batch = 16\n",
    "model_dict = {\n",
    "    'v8':  ['l', 'x'],\n",
    "    'v9':  ['c', 'e'],\n",
    "    'v10': ['l', 'x'],\n",
    "    'v11': ['l', 'x'],\n",
    "    'v12': ['l', 'x'],\n",
    "    'v13': ['l', 'x'],\n",
    "}\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "for k in model_dict.keys():\n",
    "    for s in model_dict[k]:\n",
    "        print(f'yolo{k}{s}')\n",
    "        det_time_records = []\n",
    "        model_path = f'/nfs/P111yhchen/code/detection/det_branch/{k}/yolo{k}{s}/weights/best.pt'\n",
    "        if not os.path.exists(model_path):\n",
    "            continue\n",
    "        yolo_model = YOLO(model_path)\n",
    "        model_det = yolo_model.model.to(device)\n",
    "        model_det.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            input_det = torch.randn(1, 3, 640, 640).to(device)\n",
    "            macs_det, params_det = profile(model_det, inputs=(input_det, ))\n",
    "            print(f\"detect macs: {macs_det/1e9:.3f}, detect params: {params_det/1e6:.3f}\")\n",
    "\n",
    "            for i in range(200):\n",
    "                input_det = torch.randn(batch, 3, 640, 640).to(device)\n",
    "\n",
    "                start_det = time.perf_counter()\n",
    "                res = model_det(input_det)\n",
    "                det_time_records.append(1000*(time.perf_counter()-start_det))\n",
    "            det_time_records.sort()\n",
    "            mean_det_time = sum(det_time_records[50:-50])/len(det_time_records[50:-50])\n",
    "            print(f\"detect inference: {mean_det_time/batch:.3f} ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/P111yhchen/anaconda3/envs/yolov13/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FlashAttention is not available on this device. Using scaled_dot_product_attention instead.\n",
      "Ultralytics 8.3.63 ðŸš€ Python-3.11.14 torch-2.2.2+cu121 CUDA:0 (NVIDIA A100 80GB PCIe, 81085MiB)\n",
      "YOLOv9c summary (fused): 384 layers, 25,320,790 parameters, 0 gradients, 102.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /local_data/dataset/polyp/detection/patients_complete/labels/val.cache... 679 images, 25 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 704/704 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50      mAP75  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:05<00:00,  4.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        704        734      0.671      0.628      0.668      0.495      0.433\n",
      "          hyperplastic        294        323      0.658      0.596      0.652      0.512      0.428\n",
      "               adenoma        393        411      0.683      0.659      0.684      0.479      0.438\n",
      "Speed: 0.6ms preprocess, 3.4ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
      "Results saved to \u001b[1m/home/P111yhchen/detection/yolov13/runs/detect/val\u001b[0m\n",
      "[[        152         197        2418]\n",
      " [        161         205        1924]\n",
      " [         10           9           0]]\n",
      "[0.47058823529411764, 0.49878345498783455]\n",
      "Ultralytics 8.3.63 ðŸš€ Python-3.11.14 torch-2.2.2+cu121 CUDA:0 (NVIDIA A100 80GB PCIe, 81085MiB)\n",
      "YOLOv11n summary (fused): 238 layers, 2,582,542 parameters, 0 gradients, 6.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /local_data/dataset/polyp/detection/patients_complete/labels/val.cache... 679 images, 25 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 704/704 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50      mAP75  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:04<00:00,  4.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        704        734      0.639      0.598      0.633      0.473       0.41\n",
      "          hyperplastic        294        323      0.623      0.548      0.597       0.48      0.396\n",
      "               adenoma        393        411      0.654      0.647      0.669      0.467      0.424\n",
      "Speed: 0.7ms preprocess, 1.2ms inference, 0.0ms loss, 0.6ms postprocess per image\n",
      "Results saved to \u001b[1m/home/P111yhchen/detection/yolov13/runs/detect/val2\u001b[0m\n",
      "[[        157         159        1722]\n",
      " [        149         239        1640]\n",
      " [         17          13           0]]\n",
      "[0.48606811145510836, 0.5815085158150851]\n",
      "Ultralytics 8.3.63 ðŸš€ Python-3.11.14 torch-2.2.2+cu121 CUDA:0 (NVIDIA A100 80GB PCIe, 81085MiB)\n",
      "YOLOv11s summary (fused): 238 layers, 9,413,574 parameters, 0 gradients, 21.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /local_data/dataset/polyp/detection/patients_complete/labels/val.cache... 679 images, 25 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 704/704 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50      mAP75  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:04<00:00,  4.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        704        734      0.601      0.637      0.636      0.469      0.413\n",
      "          hyperplastic        294        323      0.594      0.588      0.609      0.479      0.403\n",
      "               adenoma        393        411      0.608      0.686      0.662       0.46      0.423\n",
      "Speed: 0.6ms preprocess, 1.4ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1m/home/P111yhchen/detection/yolov13/runs/detect/val3\u001b[0m\n",
      "[[        167         175        1929]\n",
      " [        146         226        1654]\n",
      " [         10          10           0]]\n",
      "[0.5170278637770898, 0.5498783454987834]\n",
      "Ultralytics 8.3.63 ðŸš€ Python-3.11.14 torch-2.2.2+cu121 CUDA:0 (NVIDIA A100 80GB PCIe, 81085MiB)\n",
      "YOLOv11m summary (fused): 238 layers, 19,693,622 parameters, 0 gradients, 65.6 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /local_data/dataset/polyp/detection/patients_complete/labels/val.cache... 679 images, 25 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 704/704 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50      mAP75  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:05<00:00,  4.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        704        734       0.62      0.663      0.657      0.492      0.435\n",
      "          hyperplastic        294        323       0.59      0.579      0.616      0.497      0.416\n",
      "               adenoma        393        411       0.65      0.746      0.698      0.487      0.454\n",
      "Speed: 0.7ms preprocess, 2.2ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
      "Results saved to \u001b[1m/home/P111yhchen/detection/yolov13/runs/detect/val4\u001b[0m\n",
      "[[        154         146         933]\n",
      " [        149         249         931]\n",
      " [         20          16           0]]\n",
      "[0.47678018575851394, 0.6058394160583942]\n",
      "Ultralytics 8.3.63 ðŸš€ Python-3.11.14 torch-2.2.2+cu121 CUDA:0 (NVIDIA A100 80GB PCIe, 81085MiB)\n",
      "YOLOv11l summary (fused): 464 layers, 25,280,854 parameters, 0 gradients, 86.6 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /local_data/dataset/polyp/detection/patients_complete/labels/val.cache... 679 images, 25 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 704/704 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50      mAP75  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:05<00:00,  4.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        704        734       0.66      0.627      0.671      0.507      0.443\n",
      "          hyperplastic        294        323      0.625      0.622      0.658      0.519      0.441\n",
      "               adenoma        393        411      0.695      0.631      0.685      0.494      0.445\n",
      "Speed: 0.6ms preprocess, 3.1ms inference, 0.0ms loss, 0.6ms postprocess per image\n",
      "Results saved to \u001b[1m/home/P111yhchen/detection/yolov13/runs/detect/val5\u001b[0m\n",
      "[[        158         196        3582]\n",
      " [        157         210        2884]\n",
      " [          8           5           0]]\n",
      "[0.4891640866873065, 0.5109489051094891]\n",
      "Ultralytics 8.3.63 ðŸš€ Python-3.11.14 torch-2.2.2+cu121 CUDA:0 (NVIDIA A100 80GB PCIe, 81085MiB)\n",
      "YOLOv11x summary (fused): 464 layers, 56,829,334 parameters, 0 gradients, 194.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /local_data/dataset/polyp/detection/patients_complete/labels/val.cache... 679 images, 25 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 704/704 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50      mAP75  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:06<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        704        734      0.609      0.655      0.668      0.511       0.45\n",
      "          hyperplastic        294        323       0.57      0.588      0.622      0.496      0.419\n",
      "               adenoma        393        411      0.647      0.723      0.714      0.526      0.481\n",
      "Speed: 0.6ms preprocess, 5.4ms inference, 0.0ms loss, 0.6ms postprocess per image\n",
      "Results saved to \u001b[1m/home/P111yhchen/detection/yolov13/runs/detect/val6\u001b[0m\n",
      "[[        173         133         847]\n",
      " [        131         265         783]\n",
      " [         19          13           0]]\n",
      "[0.5356037151702786, 0.6447688564476886]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VIBIBLE_DEVICES']='0'\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# model_dict = {\n",
    "#     'v8':  ['n', 's', 'm', 'l', 'x'],\n",
    "#     'v9':  ['t', 's', 'm', 'c', 'e'],\n",
    "#     'v10': ['n', 's', 'm', 'b', 'l', 'x'],\n",
    "#     'v11': ['n', 's', 'm', 'l', 'x'],\n",
    "#     'v12': ['n', 's', 'm', 'l', 'x'],\n",
    "#     'v13': ['n', 's', 'l', 'x'],\n",
    "# }\n",
    "model_dict = {\n",
    "    # 'v8':  ['n', 's', 'm'],\n",
    "    'v9':  ['c'],\n",
    "    # 'v10': ['n', 's', 'm'],\n",
    "    'v11': ['n', 's', 'm', 'l', 'x'],\n",
    "    # 'v12': ['n', 's', 'm'],\n",
    "    # 'v13': ['n', 's'],\n",
    "}\n",
    "\n",
    "for k in model_dict.keys():\n",
    "    for s in model_dict[k]:\n",
    "        model_path = f'/nfs/P111yhchen/code/detection/det_branch/{k}/yolo{k}{s}/weights/best.pt'\n",
    "        if not os.path.exists(model_path):\n",
    "            continue\n",
    "        model = YOLO(model_path)\n",
    "        metrics = model.val(\n",
    "            data = 'ultralytics/cfg/datasets/polyp_2.yaml',\n",
    "            single_cls=False,\n",
    "            batch=32,\n",
    "            # conf=0.001,\n",
    "            # save_txt=True\n",
    "        )\n",
    "        confusion_matrix = metrics.confusion_matrix.matrix\n",
    "        print(confusion_matrix)\n",
    "        acc = []\n",
    "        for ci in range(len(confusion_matrix)-1):\n",
    "            acc.append(confusion_matrix[ci, ci]/confusion_matrix[:,ci].sum())\n",
    "        print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
