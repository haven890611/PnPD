{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/P111yhchen/anaconda3/envs/yolov13/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/nfs/P111yhchen/anaconda3/envs/yolov13/lib/python3.11/site-packages/albumentations/__init__.py:28: UserWarning: A new version of Albumentations is available: '2.0.8' (you have '2.0.4'). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n",
      "/nfs/P111yhchen/anaconda3/envs/yolov13/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FlashAttention is not available on this device. Using scaled_dot_product_attention instead.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "from albumentations.augmentations import transforms\n",
    "from albumentations.core.composition import Compose, OneOf\n",
    "from albumentations import RandomRotate90,Resize\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from archs import UNext\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image / label root\n",
    "image_root = \"/local_data/dataset/polyp/detection/patients_complete/images/val/\"\n",
    "label_root = \"/local_data/dataset/polyp/detection/patients_complete/labels/val/\"\n",
    "\n",
    "# ---------------------- config ----------------------\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# PolypPVT 輸入尺寸（請改成你訓練時用的大小）\n",
    "SEG_SIZE = (352, 352)  # (W, H)\n",
    "\n",
    "NUM_CLASSES_DET = 2     # hyperplastic, adenoma\n",
    "BG_INDEX_SEG = 2        # segmentation 的背景 channel index\n",
    "IOU_THRESH_EVAL = 0.5   # mAP50\n",
    "CONF_THRESH_DET = 0.001 # 要求的 detection conf 門檻"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#images in val: 704\n"
     ]
    }
   ],
   "source": [
    "# segmentation model\n",
    "model_seg = UNext(3, 3, False)\n",
    "model_seg.load_state_dict(torch.load(\n",
    "    \"/nfs/P111yhchen/code/detection/seg_branch/runs/UNeXt/best.pth\",\n",
    "    map_location=\"cpu\"\n",
    "))\n",
    "model_seg.to(device).eval()\n",
    "test_transform = Compose([\n",
    "    Resize(352, 352),\n",
    "    transforms.Normalize(),\n",
    "])\n",
    "\n",
    "\n",
    "# ---------------------- main loop ----------------------\n",
    "img_exts = (\"*.jpg\", \"*.jpeg\", \"*.png\", \"*.bmp\", \"*.tif\")\n",
    "img_paths = []\n",
    "for e in img_exts:\n",
    "    img_paths.extend(glob.glob(os.path.join(image_root, e)))\n",
    "img_paths = sorted(img_paths)\n",
    "\n",
    "print(f\"#images in val: {len(img_paths)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------- helpers ----------------------\n",
    "def load_yolo_gt(label_path, img_w, img_h, num_classes=NUM_CLASSES_DET):\n",
    "    \"\"\"\n",
    "    讀取 YOLO txt labels -> list of {cls, box=[x1,y1,x2,y2]}\n",
    "    \"\"\"\n",
    "    if not os.path.exists(label_path):\n",
    "        return {c: [] for c in range(num_classes)}\n",
    "\n",
    "    with open(label_path, \"r\") as f:\n",
    "        lines = [x.strip() for x in f.readlines() if x.strip()]\n",
    "\n",
    "    gts_per_cls = {c: [] for c in range(num_classes)}\n",
    "    if not lines:\n",
    "        return gts_per_cls\n",
    "\n",
    "    for line in lines:\n",
    "        parts = line.split()\n",
    "        if len(parts) != 5:\n",
    "            continue\n",
    "        cls = int(float(parts[0]))\n",
    "        if cls >= num_classes:\n",
    "            continue\n",
    "        xc, yc, w, h = map(float, parts[1:])\n",
    "        xc *= img_w\n",
    "        yc *= img_h\n",
    "        w *= img_w\n",
    "        h *= img_h\n",
    "        x1 = xc - w / 2\n",
    "        y1 = yc - h / 2\n",
    "        x2 = xc + w / 2\n",
    "        y2 = yc + h / 2\n",
    "        gts_per_cls[cls].append([x1, y1, x2, y2])\n",
    "\n",
    "    return gts_per_cls\n",
    "\n",
    "def infer_seg_prob_map(img_bgr):\n",
    "    \"\"\"\n",
    "    img_bgr: (H,W,3) uint8\n",
    "    return prob_map: torch.Tensor, shape (C,H,W) on CPU\n",
    "    \"\"\"\n",
    "    start_seg_pre = time.perf_counter()\n",
    "    h0, w0 = img_bgr.shape[:2]\n",
    "    img_resized = test_transform(image=img_bgr)['image']\n",
    "    img_chw = img_resized.astype('float32') / 255\n",
    "    img_chw = img_chw.transpose(2, 0, 1)\n",
    "    img_tensor = torch.from_numpy(img_chw).unsqueeze(0).to(device)\n",
    "\n",
    "    elapsed_seg_pre = (time.perf_counter() - start_seg_pre) * 1000\n",
    "    # print(f\"segmentation preprocess time: {elapsed_seg_pre:.3f} ms\")\n",
    "\n",
    "    start_seg = time.perf_counter()\n",
    "    with torch.no_grad():\n",
    "        results = model_seg(img_tensor)\n",
    "        pred_seg = F.interpolate(results, size=(h0, w0), mode=\"bilinear\", align_corners=False)\n",
    "        prob = torch.softmax(pred_seg, dim=1)[0]  # (C,H,W)\n",
    "    elapsed_seg = (time.perf_counter() - start_seg) * 1000\n",
    "    # print(f\"segmentation inference time: {elapsed_seg:.3f} ms\")\n",
    "    \n",
    "    return prob.cpu()\n",
    "\n",
    "\n",
    "def classify_box_with_seg(prob_map, box_xyxy, bg_index=BG_INDEX_SEG):\n",
    "    \"\"\"\n",
    "    用 segmentation prob map 決定 bbox 的 class\n",
    "    prob_map: (C,H,W) torch Tensor on CPU\n",
    "    box_xyxy: [x1,y1,x2,y2] in image coords\n",
    "    return det_cls (0~NUM_CLASSES_DET-1) or None (如果框無效)\n",
    "    \"\"\"\n",
    "    C, H, W = prob_map.shape\n",
    "    x1, y1, x2, y2 = box_xyxy\n",
    "    x1 = max(int(np.floor(x1)), 0)\n",
    "    y1 = max(int(np.floor(y1)), 0)\n",
    "    x2 = min(int(np.ceil(x2)), W)\n",
    "    y2 = min(int(np.ceil(y2)), H)\n",
    "\n",
    "    if x2 <= x1 or y2 <= y1:\n",
    "        return None\n",
    "    \n",
    "    # the last channel is background\n",
    "    crop = prob_map[:-1, y1:y2, x1:x2]\n",
    "    vote = crop.sum(dim=(1,2))\n",
    "    det_cls = vote.argmax(dim=0).item()\n",
    "    #det_cls = bg_index if vote[det_cls].data==0 else det_cls\n",
    "    return det_cls\n",
    "    \n",
    "def box_iou_np(box1, box2):\n",
    "    \"\"\"\n",
    "    box1: (N,4), box2:(M,4) in xyxy\n",
    "    return IoU: (N,M)\n",
    "    \"\"\"\n",
    "    if box1.size == 0 or box2.size == 0:\n",
    "        return np.zeros((box1.shape[0], box2.shape[0]))\n",
    "\n",
    "    box1 = box1.astype(np.float32)\n",
    "    box2 = box2.astype(np.float32)\n",
    "\n",
    "    area1 = np.clip(box1[:, 2] - box1[:, 0], 0, None) * np.clip(box1[:, 3] - box1[:, 1], 0, None)\n",
    "    area2 = np.clip(box2[:, 2] - box2[:, 0], 0, None) * np.clip(box2[:, 3] - box2[:, 1], 0, None)\n",
    "\n",
    "    inter_x1 = np.maximum(box1[:, None, 0], box2[None, :, 0])\n",
    "    inter_y1 = np.maximum(box1[:, None, 1], box2[None, :, 1])\n",
    "    inter_x2 = np.minimum(box1[:, None, 2], box2[None, :, 2])\n",
    "    inter_y2 = np.minimum(box1[:, None, 3], box2[None, :, 3])\n",
    "\n",
    "    inter_w = np.clip(inter_x2 - inter_x1, 0, None)\n",
    "    inter_h = np.clip(inter_y2 - inter_y1, 0, None)\n",
    "    inter = inter_w * inter_h\n",
    "\n",
    "    union = area1[:, None] + area2[None, :] - inter + 1e-16\n",
    "    return inter / union\n",
    "\n",
    "def compute_confusion_matrix(predictions,\n",
    "                             gt_boxes_per_image,\n",
    "                             num_classes=2,\n",
    "                             conf_th=0.25,\n",
    "                             iou_th=0.5):\n",
    "    \"\"\"\n",
    "    Return confusion matrix of shape (num_classes+1, num_classes+1)\n",
    "    rows:    predicted class (最後一列 = predicted background)\n",
    "    columns: ground-truth class (最後一欄 = GT background)\n",
    "    \"\"\"\n",
    "    bg = num_classes\n",
    "    cm = np.zeros((num_classes + 1, num_classes + 1), dtype=np.int64)\n",
    "\n",
    "    # 先把 prediction 按 image_id group 起來比較快\n",
    "    preds_by_img = {}\n",
    "    for p in predictions:\n",
    "        if p[\"score\"] < conf_th:\n",
    "            continue\n",
    "        preds_by_img.setdefault(p[\"image_id\"], []).append(p)\n",
    "\n",
    "    for img_id, gt_dict in gt_boxes_per_image.items():\n",
    "        # collect all GT boxes for this image\n",
    "        gt_boxes = []\n",
    "        gt_cls = []\n",
    "        for c in range(num_classes):\n",
    "            for b in gt_dict[c]:\n",
    "                gt_boxes.append(b)\n",
    "                gt_cls.append(c)\n",
    "        gt_boxes = np.array(gt_boxes, dtype=np.float32)\n",
    "        gt_cls = np.array(gt_cls, dtype=np.int64)\n",
    "\n",
    "        preds = preds_by_img.get(img_id, [])\n",
    "        if len(preds) == 0 and gt_boxes.size == 0:\n",
    "            continue\n",
    "\n",
    "        pred_boxes = np.array([p[\"box\"] for p in preds], dtype=np.float32) if preds else np.zeros((0, 4), dtype=np.float32)\n",
    "        pred_cls = np.array([p[\"cls\"] for p in preds], dtype=np.int64) if preds else np.zeros((0,), dtype=np.int64)\n",
    "\n",
    "        N, M = pred_boxes.shape[0], gt_boxes.shape[0]\n",
    "\n",
    "        if N > 0 and M > 0:\n",
    "            ious = box_iou_np(pred_boxes, gt_boxes)  # (N,M)\n",
    "            matched_pred = np.zeros(N, dtype=bool)\n",
    "            matched_gt = np.zeros(M, dtype=bool)\n",
    "\n",
    "            # greedy 1-1 matching by IoU\n",
    "            while True:\n",
    "                idx = np.unravel_index(np.argmax(ious), ious.shape)\n",
    "                max_iou = ious[idx]\n",
    "                if max_iou < iou_th:\n",
    "                    break\n",
    "                pi, gj = idx\n",
    "                if matched_pred[pi] or matched_gt[gj]:\n",
    "                    ious[pi, gj] = -1.0\n",
    "                    continue\n",
    "                matched_pred[pi] = True\n",
    "                matched_gt[gj] = True\n",
    "\n",
    "                pc = int(pred_cls[pi])\n",
    "                gc = int(gt_cls[gj])\n",
    "                cm[pc, gc] += 1\n",
    "\n",
    "                ious[pi, :] = -1.0\n",
    "                ious[:, gj] = -1.0\n",
    "\n",
    "            # unmatched predictions -> predicted some class, GT background\n",
    "            for i in range(N):\n",
    "                if not matched_pred[i]:\n",
    "                    pc = int(pred_cls[i])\n",
    "                    cm[pc, bg] += 1\n",
    "\n",
    "            # unmatched GT -> predicted background, GT some class\n",
    "            for j in range(M):\n",
    "                if not matched_gt[j]:\n",
    "                    gc = int(gt_cls[j])\n",
    "                    cm[bg, gc] += 1\n",
    "\n",
    "        elif N > 0 and M == 0:\n",
    "            # all preds are FP, GT background\n",
    "            for pc in pred_cls:\n",
    "                cm[int(pc), bg] += 1\n",
    "        elif N == 0 and M > 0:\n",
    "            # all GT are FN, predicted background\n",
    "            for gc in gt_cls:\n",
    "                cm[bg, int(gc)] += 1\n",
    "\n",
    "    return cm\n",
    "\n",
    "# -------------------  Detection Metrics (AP) ------------------------------\n",
    "def prepare_gt_class_agnostic(gt_boxes_per_image):\n",
    "    gt_nocls = {}\n",
    "    for img_id, v in gt_boxes_per_image.items():\n",
    "        boxes = []\n",
    "        if isinstance(v, dict):\n",
    "            # v: {cls: [[...], ...], ...}\n",
    "            for cls, box_list in v.items():\n",
    "                if box_list is None:\n",
    "                    continue\n",
    "                for b in box_list:\n",
    "                    boxes.append(b)\n",
    "        else:\n",
    "            # 若本來就已經是 list of boxes\n",
    "            boxes = v\n",
    "\n",
    "        if len(boxes) > 0:\n",
    "            gt_nocls[img_id] = np.asarray(boxes, dtype=np.float32).reshape(-1, 4)\n",
    "        else:\n",
    "            gt_nocls[img_id] = np.zeros((0, 4), dtype=np.float32)\n",
    "    return gt_nocls\n",
    "\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 單一 box 對多個 boxes 的 IoU\n",
    "# box: shape (4,), boxes: shape (N, 4)\n",
    "# -------------------------------------------------\n",
    "def box_iou(box, boxes):\n",
    "    if boxes.size == 0:\n",
    "        return np.zeros((0,), dtype=np.float32)\n",
    "\n",
    "    x1 = np.maximum(box[0], boxes[:, 0])\n",
    "    y1 = np.maximum(box[1], boxes[:, 1])\n",
    "    x2 = np.minimum(box[2], boxes[:, 2])\n",
    "    y2 = np.minimum(box[3], boxes[:, 3])\n",
    "\n",
    "    inter_w = np.clip(x2 - x1, a_min=0, a_max=None)\n",
    "    inter_h = np.clip(y2 - y1, a_min=0, a_max=None)\n",
    "    inter = inter_w * inter_h\n",
    "\n",
    "    area_box = (box[2] - box[0]) * (box[3] - box[1])\n",
    "    area_boxes = (boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 1])\n",
    "\n",
    "    union = area_box + area_boxes - inter\n",
    "    iou = np.where(union > 0, inter / union, 0.0)\n",
    "    return iou\n",
    "\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 計算「不分分類」的 AP@iou_thr\n",
    "# all_predictions: list of dict\n",
    "#   {\"image_id\": str, \"cls\": int, \"score\": float, \"box\": [x1,y1,x2,y2]}\n",
    "# gt_boxes_per_image: img_id -> {cls: [[x1,y1,x2,y2], ...]}\n",
    "# -------------------------------------------------\n",
    "def compute_ap_class_agnostic(all_predictions, gt_boxes_per_image, iou_thr=0.5):\n",
    "    \"\"\"\n",
    "    class-agnostic 的 AP 計算：\n",
    "    - 忽略 pred[\"cls\"]，只看 image_id / box / score。\n",
    "    - 回傳 AP + 原始 PR curve + COCO 插值後 PR + 對應的 score threshold。\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    ap : float\n",
    "        指定 IoU 門檻下的 Average Precision。\n",
    "    recalls : np.ndarray, shape (N,)\n",
    "        依照 score 從高到低加點時，每一點的 recall。\n",
    "    precisions : np.ndarray, shape (N,)\n",
    "        依照 score 從高到低加點時，每一點的 precision。\n",
    "    rec_points : np.ndarray, shape (101,)\n",
    "        COCO 風格的固定 recall 取樣點：0.00, 0.01, ..., 1.00。\n",
    "    prec_interp : np.ndarray, shape (101,)\n",
    "        對應到 rec_points 的「插值後」precision（用來算 AP 的 PR 曲線）。\n",
    "    thresholds : np.ndarray, shape (N,)\n",
    "        每一個 PR 點對應的 score threshold（第 i 個點 = 保留 score ≥ thresholds[i]）。\n",
    "    \"\"\"\n",
    "    # 先把 GT 合併成「不分 class」版本\n",
    "    gt_nocls = prepare_gt_class_agnostic(gt_boxes_per_image)\n",
    "\n",
    "    # 總 GT 數量 (所有圖、所有類別加總)\n",
    "    npos = sum(len(b) for b in gt_nocls.values())\n",
    "    if npos == 0:\n",
    "        return float(\"nan\"), None, None, None, None, None\n",
    "\n",
    "    # 依照 score 由大到小排序 (完全忽略 cls)\n",
    "    preds = sorted(all_predictions, key=lambda x: x[\"score\"], reverse=True)\n",
    "\n",
    "    tp = np.zeros(len(preds), dtype=np.float32)\n",
    "    fp = np.zeros(len(preds), dtype=np.float32)\n",
    "    thresholds = np.array([p[\"score\"] for p in preds], dtype=np.float32)\n",
    "\n",
    "    # 每張圖的每個 GT 只能被 match 一次\n",
    "    gt_used = {img_id: np.zeros(len(boxes), dtype=bool)\n",
    "               for img_id, boxes in gt_nocls.items()}\n",
    "\n",
    "    for i, p in enumerate(preds):\n",
    "        img_id = p[\"image_id\"]\n",
    "        box = np.asarray(p[\"box\"], dtype=np.float32)\n",
    "\n",
    "        gt_boxes = gt_nocls.get(img_id, None)\n",
    "        if gt_boxes is None or len(gt_boxes) == 0:\n",
    "            # 這張圖沒有 GT，任何預測都是 FP\n",
    "            fp[i] = 1.0\n",
    "            continue\n",
    "\n",
    "        ious = box_iou(box, gt_boxes)\n",
    "        max_iou_idx = int(np.argmax(ious))\n",
    "        max_iou = float(ious[max_iou_idx])\n",
    "\n",
    "        if max_iou >= iou_thr and not gt_used[img_id][max_iou_idx]:\n",
    "            tp[i] = 1.0\n",
    "            gt_used[img_id][max_iou_idx] = True\n",
    "        else:\n",
    "            fp[i] = 1.0\n",
    "\n",
    "    # ------- 原始 PR curve（每加一個預測點更新一次） -------\n",
    "    tp_cum = np.cumsum(tp)\n",
    "    fp_cum = np.cumsum(fp)\n",
    "\n",
    "    recalls = tp_cum / npos\n",
    "    precisions = tp_cum / np.maximum(tp_cum + fp_cum, 1e-8)\n",
    "\n",
    "    # ------- COCO 風格：在 0~1 的 101 個 recall 點做插值 -------\n",
    "    rec_points = np.linspace(0.0, 1.0, 101)\n",
    "    prec_interp = np.zeros_like(rec_points)\n",
    "\n",
    "    for idx, r in enumerate(rec_points):\n",
    "        # 找到所有 recall >= r 的點，取其中最大的 precision\n",
    "        mask = recalls >= r\n",
    "        if np.any(mask):\n",
    "            prec_interp[idx] = np.max(precisions[mask])\n",
    "        else:\n",
    "            prec_interp[idx] = 0.0\n",
    "\n",
    "    ap = float(np.mean(prec_interp))\n",
    "\n",
    "    return ap, recalls, precisions, rec_points, prec_interp, thresholds\n",
    "\n",
    "def find_best_f1_threshold(precisions, recalls, thresholds):\n",
    "    \"\"\"\n",
    "    根據原始 PR curve 的每個點計算 F1，找出 F1 最大的點。\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    best_thresh : float\n",
    "        讓 F1 最大的 confidence threshold（score）。\n",
    "    best_f1 : float\n",
    "        最大的 F1 值。\n",
    "    best_p : float\n",
    "        該 threshold 底下的 precision。\n",
    "    best_r : float\n",
    "        該 threshold 底下的 recall。\n",
    "    \"\"\"\n",
    "    # F1 = 2PR / (P+R)\n",
    "    denom = precisions + recalls\n",
    "    f1 = np.where(denom > 0, 2 * precisions * recalls / denom, 0.0)\n",
    "\n",
    "    if len(f1) == 0:\n",
    "        return None, None, None, None\n",
    "\n",
    "    best_idx = int(np.argmax(f1))\n",
    "    best_thresh = float(thresholds[best_idx])\n",
    "    best_f1 = float(f1[best_idx])\n",
    "    best_p = float(precisions[best_idx])\n",
    "    best_r = float(recalls[best_idx])\n",
    "    return best_thresh, best_f1, best_p, best_r\n",
    "    \n",
    "\n",
    "# -------------------------------------------------\n",
    "# 實際計算 AP@50, AP@75, AP@50:95\n",
    "# all_predictions / gt_boxes_per_image 用你 main loop 算好的那兩個變數\n",
    "# -------------------------------------------------\n",
    "# AP@50:95\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yolov11l\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating dual-path: 100%|██████████| 704/704 [00:28<00:00, 24.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion matrix @50 (rows=pred, cols=gt, last index = background):\n",
      "[[194  41  22]\n",
      " [ 76 300  51]\n",
      " [ 53  70   0]]\n",
      "[class 0] precision: 0.7549  recall: 0.6006 \n",
      "[class 1] precision: 0.7026  recall: 0.7299 \n",
      "AP@50:95: 0.5737\n",
      "[IoU=0.5] best threshold = 0.4578\n",
      "[IoU=0.5] AP = 0.8964\n",
      "[IoU=0.5] precision = 0.8933, recall = 0.8324\n",
      "[IoU=0.5] best F1 = 0.8618\n",
      "yolov11x\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating dual-path: 100%|██████████| 704/704 [00:27<00:00, 25.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion matrix @50 (rows=pred, cols=gt, last index = background):\n",
      "[[200  41  16]\n",
      " [ 76 305  54]\n",
      " [ 47  65   0]]\n",
      "[class 0] precision: 0.7782  recall: 0.6192 \n",
      "[class 1] precision: 0.7011  recall: 0.7421 \n",
      "AP@50:95: 0.5796\n",
      "[IoU=0.5] best threshold = 0.4510\n",
      "[IoU=0.5] AP = 0.9105\n",
      "[IoU=0.5] precision = 0.8988, recall = 0.8474\n",
      "[IoU=0.5] best F1 = 0.8724\n",
      "yolov12l\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating dual-path: 100%|██████████| 704/704 [00:31<00:00, 22.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion matrix @50 (rows=pred, cols=gt, last index = background):\n",
      "[[199  47  25]\n",
      " [ 76 311  75]\n",
      " [ 48  53   0]]\n",
      "[class 0] precision: 0.7343  recall: 0.6161 \n",
      "[class 1] precision: 0.6732  recall: 0.7567 \n",
      "AP@50:95: 0.5797\n",
      "[IoU=0.5] best threshold = 0.3743\n",
      "[IoU=0.5] AP = 0.8966\n",
      "[IoU=0.5] precision = 0.8636, recall = 0.8624\n",
      "[IoU=0.5] best F1 = 0.8630\n",
      "yolov12x\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating dual-path: 100%|██████████| 704/704 [00:30<00:00, 23.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion matrix @50 (rows=pred, cols=gt, last index = background):\n",
      "[[199  42  26]\n",
      " [ 77 302  55]\n",
      " [ 47  67   0]]\n",
      "[class 0] precision: 0.7453  recall: 0.6161 \n",
      "[class 1] precision: 0.6959  recall: 0.7348 \n",
      "AP@50:95: 0.5826\n",
      "[IoU=0.5] best threshold = 0.4298\n",
      "[IoU=0.5] AP = 0.9007\n",
      "[IoU=0.5] precision = 0.8845, recall = 0.8447\n",
      "[IoU=0.5] best F1 = 0.8641\n",
      "yolov13l\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating dual-path: 100%|██████████| 704/704 [00:33<00:00, 20.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion matrix @50 (rows=pred, cols=gt, last index = background):\n",
      "[[200  42  23]\n",
      " [ 80 304  63]\n",
      " [ 43  65   0]]\n",
      "[class 0] precision: 0.7547  recall: 0.6192 \n",
      "[class 1] precision: 0.6801  recall: 0.7397 \n",
      "AP@50:95: 0.5722\n",
      "[IoU=0.5] best threshold = 0.3025\n",
      "[IoU=0.5] AP = 0.8950\n",
      "[IoU=0.5] precision = 0.8792, recall = 0.8529\n",
      "[IoU=0.5] best F1 = 0.8658\n",
      "yolov13x\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating dual-path: 100%|██████████| 704/704 [00:35<00:00, 20.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion matrix @50 (rows=pred, cols=gt, last index = background):\n",
      "[[192  37  19]\n",
      " [ 76 299  66]\n",
      " [ 55  75   0]]\n",
      "[class 0] precision: 0.7742  recall: 0.5944 \n",
      "[class 1] precision: 0.6780  recall: 0.7275 \n",
      "AP@50:95: 0.5712\n",
      "[IoU=0.5] best threshold = 0.4517\n",
      "[IoU=0.5] AP = 0.8939\n",
      "[IoU=0.5] precision = 0.8766, recall = 0.8229\n",
      "[IoU=0.5] best F1 = 0.8489\n"
     ]
    }
   ],
   "source": [
    "# model_dict = {\n",
    "#     'v8':  ['n', 's', 'm'],\n",
    "#     'v9':  ['t', 's', 'm'],\n",
    "#     'v10': ['n', 's', 'm'],\n",
    "#     'v11': ['n', 's', 'm'],\n",
    "#     'v12': ['n', 's', 'm'],\n",
    "#     'v13': ['n', 's'],\n",
    "# }\n",
    "model_dict = {\n",
    "    'v11': ['l', 'x'],\n",
    "    'v12': ['l', 'x'],\n",
    "    'v13': ['l', 'x'],\n",
    "}\n",
    "for k in model_dict.keys():\n",
    "    for s in model_dict[k]:\n",
    "        # detection model (YOLOv13-n)\n",
    "\n",
    "        model_path = f'/nfs/P111yhchen/code/detection/det_branch/{k}/yolo{k}{s}_single/weights/best.pt'\n",
    "        if not os.path.exists(model_path):\n",
    "            continue\n",
    "        print(f'yolo{k}{s}')\n",
    "        model_det = YOLO(model_path)\n",
    "\n",
    "        all_predictions = []  # 全部 pred bbox\n",
    "        gt_boxes_per_image = {}  # img_id -> {cls: [[x1,y1,x2,y2], ...]}\n",
    "\n",
    "        for img_path in tqdm(img_paths, desc=\"Evaluating dual-path\"):\n",
    "            img_id = os.path.splitext(os.path.basename(img_path))[0]\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is None:\n",
    "                continue\n",
    "            h0, w0 = img.shape[:2]\n",
    "\n",
    "            # ------ GT ------\n",
    "            label_path = os.path.join(label_root, img_id + \".txt\")\n",
    "            gt_boxes_per_image[img_id] = load_yolo_gt(label_path, w0, h0)\n",
    "\n",
    "            # ------ segmentation ------\n",
    "            prob_map = infer_seg_prob_map(img)  # (C,H,W)\n",
    "            \n",
    "\n",
    "            # ------ detection (YOLO) ------\n",
    "            # Ultralytics: conf threshold 在這裡設定\n",
    "            results = model_det.predict(\n",
    "                img,  # BGR numpy\n",
    "                single_cls=True,\n",
    "                conf=CONF_THRESH_DET,\n",
    "                iou=0.7,     # NMS 的 IoU 門檻，依需要調\n",
    "                verbose=False,\n",
    "                device=device,\n",
    "            )\n",
    "            \n",
    "            r = results[0]\n",
    "            if r.boxes is None or len(r.boxes) == 0:\n",
    "                continue\n",
    "\n",
    "            boxes = r.boxes.xyxy.cpu().numpy()\n",
    "            scores = r.boxes.conf.cpu().numpy()\n",
    "            \n",
    "            for box, score in zip(boxes, scores):\n",
    "                start_map = time.perf_counter()\n",
    "                det_cls = classify_box_with_seg(prob_map, box)\n",
    "                elapsed_map = (time.perf_counter() - start_map) * 1000\n",
    "                # print(f\"map and vote time: {elapsed_map:.3f} ms\")\n",
    "                if det_cls is None:\n",
    "                    continue\n",
    "                all_predictions.append({\n",
    "                    \"image_id\": img_id,\n",
    "                    \"cls\": int(det_cls),\n",
    "                    \"score\": float(score),\n",
    "                    \"box\": box.tolist(),\n",
    "                })\n",
    "\n",
    "        aps = []\n",
    "        thrs = [] # conf_thr with best F1 score\n",
    "        rs = [] \n",
    "        ps = []\n",
    "        for thr in np.arange(0.5, 1.0, 0.05):  # 0.50, 0.55, ..., 0.95\n",
    "            ap_i, r_i, p_i, _, _, thr_i = compute_ap_class_agnostic(\n",
    "                all_predictions, gt_boxes_per_image, iou_thr=thr\n",
    "            )\n",
    "            aps.append(ap_i)\n",
    "            thrs.append(thr_i)\n",
    "            rs.append(r_i)\n",
    "            ps.append(p_i)\n",
    "        ap_50_95 = float(np.mean(aps))\n",
    "        best_thr_50, best_f1_50, best_p_50, best_r_50 = find_best_f1_threshold(ps[0], rs[0], thrs[0])\n",
    "        cm = compute_confusion_matrix(\n",
    "            all_predictions,\n",
    "            gt_boxes_per_image,\n",
    "            num_classes=NUM_CLASSES_DET,\n",
    "            conf_th=best_thr_50,   # 想和 ultralytics 一樣就設 0.25\n",
    "            iou_th=0.5\n",
    "        )\n",
    "        print(\"\\nConfusion matrix @50 (rows=pred, cols=gt, last index = background):\")\n",
    "        print(cm)\n",
    "        for ci in range(NUM_CLASSES_DET):\n",
    "            pp = cm[ci, ci]/cm[ci].sum()\n",
    "            rr = cm[ci, ci]/cm[:, ci].sum()\n",
    "            print(f\"[class {ci}] precision: {pp:.4f}  recall: {rr:.4f} \")\n",
    "\n",
    "        print(f\"AP@50:95: {ap_50_95:.4f}\")\n",
    "\n",
    "        print(f\"[IoU=0.5] best threshold = {best_thr_50:.4f}\")\n",
    "        print(f\"[IoU=0.5] AP = {aps[0]:.4f}\")\n",
    "        print(f\"[IoU=0.5] precision = {best_p_50:.4f}, recall = {best_r_50:.4f}\")\n",
    "        print(f\"[IoU=0.5] best F1 = {best_f1_50:.4f}\")\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
