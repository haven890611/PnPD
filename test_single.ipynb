{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/P111yhchen/anaconda3/envs/yolov13/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FlashAttention is not available on this device. Using scaled_dot_product_attention instead.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# image / label root\n",
    "image_root = \"/local_data/dataset/polyp/detection/patients_complete/images/val/\"\n",
    "label_root = \"/local_data/dataset/polyp/detection/patients_complete/labels/val/\"\n",
    "\n",
    "# seg normalize\n",
    "mean = torch.Tensor([0.485, 0.456, 0.406]).view(1, 3, 1, 1).to(device)\n",
    "std = torch.Tensor([0.229, 0.224, 0.225]).view(1, 3, 1, 1).to(device)\n",
    "\n",
    "NUM_CLASSES_DET = 2     # hyperplastic, adenoma\n",
    "BG_INDEX_SEG = 2        # segmentation 的背景 channel index\n",
    "CONF_THRESH_DET = 0.001 # 要求的 detection conf 門檻"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------------------- helpers ----------------------\n",
    "def load_yolo_gt(label_path, img_w, img_h, num_classes=NUM_CLASSES_DET):\n",
    "    \"\"\"\n",
    "    讀取 YOLO txt labels -> list of {cls, box=[x1,y1,x2,y2]}\n",
    "    \"\"\"\n",
    "    if not os.path.exists(label_path):\n",
    "        return {c: [] for c in range(num_classes)}\n",
    "\n",
    "    with open(label_path, \"r\") as f:\n",
    "        lines = [x.strip() for x in f.readlines() if x.strip()]\n",
    "\n",
    "    gts_per_cls = {c: [] for c in range(num_classes)}\n",
    "    if not lines:\n",
    "        return gts_per_cls\n",
    "\n",
    "    for line in lines:\n",
    "        parts = line.split()\n",
    "        if len(parts) != 5:\n",
    "            continue\n",
    "        cls = int(float(parts[0]))\n",
    "        if cls >= num_classes:\n",
    "            continue\n",
    "        xc, yc, w, h = map(float, parts[1:])\n",
    "        xc *= img_w\n",
    "        yc *= img_h\n",
    "        w *= img_w\n",
    "        h *= img_h\n",
    "        x1 = xc - w / 2\n",
    "        y1 = yc - h / 2\n",
    "        x2 = xc + w / 2\n",
    "        y2 = yc + h / 2\n",
    "        gts_per_cls[cls].append([x1, y1, x2, y2])\n",
    "\n",
    "    return gts_per_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------  Detection Metrics (AP) ------------------------------\n",
    "def prepare_gt_class_agnostic(gt_boxes_per_image):\n",
    "    gt_nocls = {}\n",
    "    for img_id, v in gt_boxes_per_image.items():\n",
    "        boxes = []\n",
    "        if isinstance(v, dict):\n",
    "            # v: {cls: [[...], ...], ...}\n",
    "            for cls, box_list in v.items():\n",
    "                if box_list is None:\n",
    "                    continue\n",
    "                for b in box_list:\n",
    "                    boxes.append(b)\n",
    "        else:\n",
    "            # 若本來就已經是 list of boxes\n",
    "            boxes = v\n",
    "\n",
    "        if len(boxes) > 0:\n",
    "            gt_nocls[img_id] = np.asarray(boxes, dtype=np.float32).reshape(-1, 4)\n",
    "        else:\n",
    "            gt_nocls[img_id] = np.zeros((0, 4), dtype=np.float32)\n",
    "    return gt_nocls\n",
    "\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 單一 box 對多個 boxes 的 IoU\n",
    "# box: shape (4,), boxes: shape (N, 4)\n",
    "# -------------------------------------------------\n",
    "def box_iou(box, boxes):\n",
    "    if boxes.size == 0:\n",
    "        return np.zeros((0,), dtype=np.float32)\n",
    "\n",
    "    x1 = np.maximum(box[0], boxes[:, 0])\n",
    "    y1 = np.maximum(box[1], boxes[:, 1])\n",
    "    x2 = np.minimum(box[2], boxes[:, 2])\n",
    "    y2 = np.minimum(box[3], boxes[:, 3])\n",
    "\n",
    "    inter_w = np.clip(x2 - x1, a_min=0, a_max=None)\n",
    "    inter_h = np.clip(y2 - y1, a_min=0, a_max=None)\n",
    "    inter = inter_w * inter_h\n",
    "\n",
    "    area_box = (box[2] - box[0]) * (box[3] - box[1])\n",
    "    area_boxes = (boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 1])\n",
    "\n",
    "    union = area_box + area_boxes - inter\n",
    "    iou = np.where(union > 0, inter / union, 0.0)\n",
    "    return iou\n",
    "\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 計算「不分分類」的 AP@iou_thr\n",
    "# all_predictions: list of dict\n",
    "#   {\"image_id\": str, \"cls\": int, \"score\": float, \"box\": [x1,y1,x2,y2]}\n",
    "# gt_boxes_per_image: img_id -> {cls: [[x1,y1,x2,y2], ...]}\n",
    "# -------------------------------------------------\n",
    "def compute_ap_class_agnostic(all_predictions, gt_boxes_per_image, iou_thr=0.5):\n",
    "    \"\"\"\n",
    "    class-agnostic 的 AP 計算：\n",
    "    - 忽略 pred[\"cls\"]，只看 image_id / box / score。\n",
    "    - 回傳 AP + 原始 PR curve + COCO 插值後 PR + 對應的 score threshold。\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    ap : float\n",
    "        指定 IoU 門檻下的 Average Precision。\n",
    "    recalls : np.ndarray, shape (N,)\n",
    "        依照 score 從高到低加點時，每一點的 recall。\n",
    "    precisions : np.ndarray, shape (N,)\n",
    "        依照 score 從高到低加點時，每一點的 precision。\n",
    "    rec_points : np.ndarray, shape (101,)\n",
    "        COCO 風格的固定 recall 取樣點：0.00, 0.01, ..., 1.00。\n",
    "    prec_interp : np.ndarray, shape (101,)\n",
    "        對應到 rec_points 的「插值後」precision（用來算 AP 的 PR 曲線）。\n",
    "    thresholds : np.ndarray, shape (N,)\n",
    "        每一個 PR 點對應的 score threshold（第 i 個點 = 保留 score ≥ thresholds[i]）。\n",
    "    \"\"\"\n",
    "    # 先把 GT 合併成「不分 class」版本\n",
    "    gt_nocls = prepare_gt_class_agnostic(gt_boxes_per_image)\n",
    "\n",
    "    # 總 GT 數量 (所有圖、所有類別加總)\n",
    "    npos = sum(len(b) for b in gt_nocls.values())\n",
    "    if npos == 0:\n",
    "        return float(\"nan\"), None, None, None, None, None\n",
    "\n",
    "    # 依照 score 由大到小排序 (完全忽略 cls)\n",
    "    preds = sorted(all_predictions, key=lambda x: x[\"score\"], reverse=True)\n",
    "\n",
    "    tp = np.zeros(len(preds), dtype=np.float32)\n",
    "    fp = np.zeros(len(preds), dtype=np.float32)\n",
    "    thresholds = np.array([p[\"score\"] for p in preds], dtype=np.float32)\n",
    "\n",
    "    # 每張圖的每個 GT 只能被 match 一次\n",
    "    gt_used = {img_id: np.zeros(len(boxes), dtype=bool)\n",
    "               for img_id, boxes in gt_nocls.items()}\n",
    "\n",
    "    for i, p in enumerate(preds):\n",
    "        img_id = p[\"image_id\"]\n",
    "        box = np.asarray(p[\"box\"], dtype=np.float32)\n",
    "\n",
    "        gt_boxes = gt_nocls.get(img_id, None)\n",
    "        if gt_boxes is None or len(gt_boxes) == 0:\n",
    "            # 這張圖沒有 GT，任何預測都是 FP\n",
    "            fp[i] = 1.0\n",
    "            continue\n",
    "\n",
    "        ious = box_iou(box, gt_boxes)\n",
    "        max_iou_idx = int(np.argmax(ious))\n",
    "        max_iou = float(ious[max_iou_idx])\n",
    "\n",
    "        if max_iou >= iou_thr and not gt_used[img_id][max_iou_idx]:\n",
    "            tp[i] = 1.0\n",
    "            gt_used[img_id][max_iou_idx] = True\n",
    "        else:\n",
    "            fp[i] = 1.0\n",
    "\n",
    "    # ------- 原始 PR curve（每加一個預測點更新一次） -------\n",
    "    tp_cum = np.cumsum(tp)\n",
    "    fp_cum = np.cumsum(fp)\n",
    "\n",
    "    recalls = tp_cum / npos\n",
    "    precisions = tp_cum / np.maximum(tp_cum + fp_cum, 1e-8)\n",
    "\n",
    "    # ------- COCO 風格：在 0~1 的 101 個 recall 點做插值 -------\n",
    "    rec_points = np.linspace(0.0, 1.0, 101)\n",
    "    prec_interp = np.zeros_like(rec_points)\n",
    "\n",
    "    for idx, r in enumerate(rec_points):\n",
    "        # 找到所有 recall >= r 的點，取其中最大的 precision\n",
    "        mask = recalls >= r\n",
    "        if np.any(mask):\n",
    "            prec_interp[idx] = np.max(precisions[mask])\n",
    "        else:\n",
    "            prec_interp[idx] = 0.0\n",
    "\n",
    "    ap = float(np.mean(prec_interp))\n",
    "\n",
    "    return ap, recalls, precisions, rec_points, prec_interp, thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_f1_threshold(precisions, recalls, thresholds):\n",
    "    \"\"\"\n",
    "    根據原始 PR curve 的每個點計算 F1，找出 F1 最大的點。\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    best_thresh : float\n",
    "        讓 F1 最大的 confidence threshold（score）。\n",
    "    best_f1 : float\n",
    "        最大的 F1 值。\n",
    "    best_p : float\n",
    "        該 threshold 底下的 precision。\n",
    "    best_r : float\n",
    "        該 threshold 底下的 recall。\n",
    "    \"\"\"\n",
    "    # F1 = 2PR / (P+R)\n",
    "    denom = precisions + recalls\n",
    "    f1 = np.where(denom > 0, 2 * precisions * recalls / denom, 0.0)\n",
    "\n",
    "    if len(f1) == 0:\n",
    "        return None, None, None, None\n",
    "\n",
    "    best_idx = int(np.argmax(f1))\n",
    "    best_thresh = float(thresholds[best_idx])\n",
    "    best_f1 = float(f1[best_idx])\n",
    "    best_p = float(precisions[best_idx])\n",
    "    best_r = float(recalls[best_idx])\n",
    "    return best_thresh, best_f1, best_p, best_r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_iou_np(box1, box2):\n",
    "    \"\"\"\n",
    "    box1: (N,4), box2:(M,4) in xyxy\n",
    "    return IoU: (N,M)\n",
    "    \"\"\"\n",
    "    if box1.size == 0 or box2.size == 0:\n",
    "        return np.zeros((box1.shape[0], box2.shape[0]))\n",
    "\n",
    "    box1 = box1.astype(np.float32)\n",
    "    box2 = box2.astype(np.float32)\n",
    "\n",
    "    area1 = np.clip(box1[:, 2] - box1[:, 0], 0, None) * np.clip(box1[:, 3] - box1[:, 1], 0, None)\n",
    "    area2 = np.clip(box2[:, 2] - box2[:, 0], 0, None) * np.clip(box2[:, 3] - box2[:, 1], 0, None)\n",
    "\n",
    "    inter_x1 = np.maximum(box1[:, None, 0], box2[None, :, 0])\n",
    "    inter_y1 = np.maximum(box1[:, None, 1], box2[None, :, 1])\n",
    "    inter_x2 = np.minimum(box1[:, None, 2], box2[None, :, 2])\n",
    "    inter_y2 = np.minimum(box1[:, None, 3], box2[None, :, 3])\n",
    "\n",
    "    inter_w = np.clip(inter_x2 - inter_x1, 0, None)\n",
    "    inter_h = np.clip(inter_y2 - inter_y1, 0, None)\n",
    "    inter = inter_w * inter_h\n",
    "\n",
    "    union = area1[:, None] + area2[None, :] - inter + 1e-16\n",
    "    return inter / union\n",
    "\n",
    "def compute_confusion_matrix(predictions,\n",
    "                             gt_boxes_per_image,\n",
    "                             num_classes=2,\n",
    "                             conf_th=0.25,\n",
    "                             iou_th=0.5):\n",
    "    \"\"\"\n",
    "    Return confusion matrix of shape (num_classes+1, num_classes+1)\n",
    "    rows:    predicted class (最後一列 = predicted background)\n",
    "    columns: ground-truth class (最後一欄 = GT background)\n",
    "    \"\"\"\n",
    "    bg = num_classes\n",
    "    cm = np.zeros((num_classes + 1, num_classes + 1), dtype=np.int64)\n",
    "\n",
    "    # 先把 prediction 按 image_id group 起來比較快\n",
    "    preds_by_img = {}\n",
    "    for p in predictions:\n",
    "        if p[\"score\"] < conf_th:\n",
    "            continue\n",
    "        preds_by_img.setdefault(p[\"image_id\"], []).append(p)\n",
    "\n",
    "    for img_id, gt_dict in gt_boxes_per_image.items():\n",
    "        # collect all GT boxes for this image\n",
    "        gt_boxes = []\n",
    "        gt_cls = []\n",
    "        for c in range(num_classes):\n",
    "            for b in gt_dict[c]:\n",
    "                gt_boxes.append(b)\n",
    "                gt_cls.append(c)\n",
    "        gt_boxes = np.array(gt_boxes, dtype=np.float32)\n",
    "        gt_cls = np.array(gt_cls, dtype=np.int64)\n",
    "\n",
    "        preds = preds_by_img.get(img_id, [])\n",
    "        if len(preds) == 0 and gt_boxes.size == 0:\n",
    "            continue\n",
    "\n",
    "        pred_boxes = np.array([p[\"box\"] for p in preds], dtype=np.float32) if preds else np.zeros((0, 4), dtype=np.float32)\n",
    "        pred_cls = np.array([p[\"cls\"] for p in preds], dtype=np.int64) if preds else np.zeros((0,), dtype=np.int64)\n",
    "\n",
    "        N, M = pred_boxes.shape[0], gt_boxes.shape[0]\n",
    "\n",
    "        if N > 0 and M > 0:\n",
    "            ious = box_iou_np(pred_boxes, gt_boxes)  # (N,M)\n",
    "            matched_pred = np.zeros(N, dtype=bool)\n",
    "            matched_gt = np.zeros(M, dtype=bool)\n",
    "\n",
    "            # greedy 1-1 matching by IoU\n",
    "            while True:\n",
    "                idx = np.unravel_index(np.argmax(ious), ious.shape)\n",
    "                max_iou = ious[idx]\n",
    "                if max_iou < iou_th:\n",
    "                    break\n",
    "                pi, gj = idx\n",
    "                if matched_pred[pi] or matched_gt[gj]:\n",
    "                    ious[pi, gj] = -1.0\n",
    "                    continue\n",
    "                matched_pred[pi] = True\n",
    "                matched_gt[gj] = True\n",
    "\n",
    "                pc = int(pred_cls[pi])\n",
    "                gc = int(gt_cls[gj])\n",
    "                cm[pc, gc] += 1\n",
    "\n",
    "                ious[pi, :] = -1.0\n",
    "                ious[:, gj] = -1.0\n",
    "\n",
    "            # unmatched predictions -> predicted some class, GT background\n",
    "            for i in range(N):\n",
    "                if not matched_pred[i]:\n",
    "                    pc = int(pred_cls[i])\n",
    "                    cm[pc, bg] += 1\n",
    "\n",
    "            # unmatched GT -> predicted background, GT some class\n",
    "            for j in range(M):\n",
    "                if not matched_gt[j]:\n",
    "                    gc = int(gt_cls[j])\n",
    "                    cm[bg, gc] += 1\n",
    "\n",
    "        elif N > 0 and M == 0:\n",
    "            # all preds are FP, GT background\n",
    "            for pc in pred_cls:\n",
    "                cm[int(pc), bg] += 1\n",
    "        elif N == 0 and M > 0:\n",
    "            # all GT are FN, predicted background\n",
    "            for gc in gt_cls:\n",
    "                cm[bg, int(gc)] += 1\n",
    "\n",
    "    return cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "v11 n\n",
      "#images in val: 704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating dual-path: 100%|██████████| 704/704 [00:27<00:00, 25.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AP@50:95: 0.5400\n",
      "[IoU=0.5] AP = 0.8476\n",
      "[IoU=0.5] best F1 = 0.7964\n",
      "[IoU=0.5] best threshold = 0.2817\n",
      "[IoU=0.5] precision = 0.8070, recall = 0.7861\n",
      "\n",
      "Confusion matrix @50 (rows=pred, cols=gt, last index = background):\n",
      "[[161  61  61]\n",
      " [ 93 262  77]\n",
      " [ 69  88   0]]\n",
      "[class 0] precision: 0.5689  recall: 0.4985 \n",
      "[class 1] precision: 0.6065  recall: 0.6375 \n",
      "\n",
      "\n",
      "v11 s\n",
      "#images in val: 704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating dual-path: 100%|██████████| 704/704 [00:11<00:00, 60.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AP@50:95: 0.5512\n",
      "[IoU=0.5] AP = 0.8643\n",
      "[IoU=0.5] best F1 = 0.8161\n",
      "[IoU=0.5] best threshold = 0.3622\n",
      "[IoU=0.5] precision = 0.8453, recall = 0.7888\n",
      "\n",
      "Confusion matrix @50 (rows=pred, cols=gt, last index = background):\n",
      "[[150  66  41]\n",
      " [106 257  65]\n",
      " [ 67  88   0]]\n",
      "[class 0] precision: 0.5837  recall: 0.4644 \n",
      "[class 1] precision: 0.6005  recall: 0.6253 \n",
      "\n",
      "\n",
      "v11 m\n",
      "#images in val: 704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating dual-path: 100%|██████████| 704/704 [00:11<00:00, 59.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AP@50:95: 0.5608\n",
      "[IoU=0.5] AP = 0.8897\n",
      "[IoU=0.5] best F1 = 0.8405\n",
      "[IoU=0.5] best threshold = 0.3917\n",
      "[IoU=0.5] precision = 0.8891, recall = 0.7970\n",
      "\n",
      "Confusion matrix @50 (rows=pred, cols=gt, last index = background):\n",
      "[[159  63  35]\n",
      " [ 90 273  38]\n",
      " [ 74  75   0]]\n",
      "[class 0] precision: 0.6187  recall: 0.4923 \n",
      "[class 1] precision: 0.6808  recall: 0.6642 \n",
      "\n",
      "\n",
      "v11 l\n",
      "#images in val: 704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating dual-path: 100%|██████████| 704/704 [00:15<00:00, 46.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AP@50:95: 0.5651\n",
      "[IoU=0.5] AP = 0.8727\n",
      "[IoU=0.5] best F1 = 0.8156\n",
      "[IoU=0.5] best threshold = 0.3104\n",
      "[IoU=0.5] precision = 0.8207, recall = 0.8106\n",
      "\n",
      "Confusion matrix @50 (rows=pred, cols=gt, last index = background):\n",
      "[[190  78  67]\n",
      " [ 78 249  63]\n",
      " [ 55  84   0]]\n",
      "[class 0] precision: 0.5672  recall: 0.5882 \n",
      "[class 1] precision: 0.6385  recall: 0.6058 \n",
      "\n",
      "\n",
      "v11 x\n",
      "#images in val: 704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating dual-path: 100%|██████████| 704/704 [00:15<00:00, 44.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AP@50:95: 0.5696\n",
      "[IoU=0.5] AP = 0.8870\n",
      "[IoU=0.5] best F1 = 0.8363\n",
      "[IoU=0.5] best threshold = 0.4148\n",
      "[IoU=0.5] precision = 0.8797, recall = 0.7970\n",
      "\n",
      "Confusion matrix @50 (rows=pred, cols=gt, last index = background):\n",
      "[[165  76  37]\n",
      " [ 80 264  43]\n",
      " [ 78  71   0]]\n",
      "[class 0] precision: 0.5935  recall: 0.5108 \n",
      "[class 1] precision: 0.6822  recall: 0.6423 \n",
      "\n",
      "\n",
      "v12 n\n",
      "#images in val: 704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating dual-path: 100%|██████████| 704/704 [00:14<00:00, 47.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AP@50:95: 0.5375\n",
      "[IoU=0.5] AP = 0.8504\n",
      "[IoU=0.5] best F1 = 0.8048\n",
      "[IoU=0.5] best threshold = 0.3706\n",
      "[IoU=0.5] precision = 0.8368, recall = 0.7752\n",
      "\n",
      "Confusion matrix @50 (rows=pred, cols=gt, last index = background):\n",
      "[[158  56  41]\n",
      " [ 97 258  70]\n",
      " [ 68  97   0]]\n",
      "[class 0] precision: 0.6196  recall: 0.4892 \n",
      "[class 1] precision: 0.6071  recall: 0.6277 \n",
      "\n",
      "\n",
      "v12 s\n",
      "#images in val: 704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating dual-path: 100%|██████████| 704/704 [00:14<00:00, 47.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AP@50:95: 0.5708\n",
      "[IoU=0.5] AP = 0.8920\n",
      "[IoU=0.5] best F1 = 0.8510\n",
      "[IoU=0.5] best threshold = 0.4289\n",
      "[IoU=0.5] precision = 0.8973, recall = 0.8093\n",
      "\n",
      "Confusion matrix @50 (rows=pred, cols=gt, last index = background):\n",
      "[[180  69  35]\n",
      " [ 84 261  33]\n",
      " [ 59  81   0]]\n",
      "[class 0] precision: 0.6338  recall: 0.5573 \n",
      "[class 1] precision: 0.6905  recall: 0.6350 \n",
      "\n",
      "\n",
      "v12 m\n",
      "#images in val: 704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating dual-path: 100%|██████████| 704/704 [00:15<00:00, 46.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AP@50:95: 0.5756\n",
      "[IoU=0.5] AP = 0.8941\n",
      "[IoU=0.5] best F1 = 0.8450\n",
      "[IoU=0.5] best threshold = 0.4811\n",
      "[IoU=0.5] precision = 0.8839, recall = 0.8093\n",
      "\n",
      "Confusion matrix @50 (rows=pred, cols=gt, last index = background):\n",
      "[[185  76  37]\n",
      " [ 81 252  41]\n",
      " [ 57  83   0]]\n",
      "[class 0] precision: 0.6208  recall: 0.5728 \n",
      "[class 1] precision: 0.6738  recall: 0.6131 \n",
      "\n",
      "\n",
      "v12 l\n",
      "#images in val: 704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating dual-path: 100%|██████████| 704/704 [00:20<00:00, 33.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AP@50:95: 0.5566\n",
      "[IoU=0.5] AP = 0.8741\n",
      "[IoU=0.5] best F1 = 0.8349\n",
      "[IoU=0.5] best threshold = 0.4495\n",
      "[IoU=0.5] precision = 0.8782, recall = 0.7956\n",
      "\n",
      "Confusion matrix @50 (rows=pred, cols=gt, last index = background):\n",
      "[[179  61  32]\n",
      " [ 85 259  49]\n",
      " [ 59  91   0]]\n",
      "[class 0] precision: 0.6581  recall: 0.5542 \n",
      "[class 1] precision: 0.6590  recall: 0.6302 \n",
      "\n",
      "\n",
      "v12 x\n",
      "#images in val: 704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating dual-path: 100%|██████████| 704/704 [00:21<00:00, 32.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AP@50:95: 0.5685\n",
      "[IoU=0.5] AP = 0.8799\n",
      "[IoU=0.5] best F1 = 0.8306\n",
      "[IoU=0.5] best threshold = 0.4412\n",
      "[IoU=0.5] precision = 0.8737, recall = 0.7916\n",
      "\n",
      "Confusion matrix @50 (rows=pred, cols=gt, last index = background):\n",
      "[[174  65  42]\n",
      " [ 80 262  42]\n",
      " [ 69  84   0]]\n",
      "[class 0] precision: 0.6192  recall: 0.5387 \n",
      "[class 1] precision: 0.6823  recall: 0.6375 \n",
      "\n",
      "\n",
      "v13 n\n",
      "#images in val: 704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating dual-path: 100%|██████████| 704/704 [00:18<00:00, 38.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AP@50:95: 0.4722\n",
      "[IoU=0.5] AP = 0.7748\n",
      "[IoU=0.5] best F1 = 0.7325\n",
      "[IoU=0.5] best threshold = 0.2528\n",
      "[IoU=0.5] precision = 0.7599, recall = 0.7071\n",
      "\n",
      "Confusion matrix @50 (rows=pred, cols=gt, last index = background):\n",
      "[[163  59  85]\n",
      " [ 60 237  79]\n",
      " [100 115   0]]\n",
      "[class 0] precision: 0.5309  recall: 0.5046 \n",
      "[class 1] precision: 0.6303  recall: 0.5766 \n",
      "\n",
      "\n",
      "v13 s\n",
      "#images in val: 704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating dual-path: 100%|██████████| 704/704 [00:18<00:00, 38.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AP@50:95: 0.5260\n",
      "[IoU=0.5] AP = 0.8419\n",
      "[IoU=0.5] best F1 = 0.7931\n",
      "[IoU=0.5] best threshold = 0.4693\n",
      "[IoU=0.5] precision = 0.8777, recall = 0.7234\n",
      "\n",
      "Confusion matrix @50 (rows=pred, cols=gt, last index = background):\n",
      "[[160  48  19]\n",
      " [ 82 241  55]\n",
      " [ 81 122   0]]\n",
      "[class 0] precision: 0.7048  recall: 0.4954 \n",
      "[class 1] precision: 0.6376  recall: 0.5864 \n",
      "\n",
      "\n",
      "v13 l\n",
      "#images in val: 704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating dual-path: 100%|██████████| 704/704 [00:25<00:00, 27.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AP@50:95: 0.5578\n",
      "[IoU=0.5] AP = 0.8713\n",
      "[IoU=0.5] best F1 = 0.8224\n",
      "[IoU=0.5] best threshold = 0.3787\n",
      "[IoU=0.5] precision = 0.8557, recall = 0.7916\n",
      "\n",
      "Confusion matrix @50 (rows=pred, cols=gt, last index = background):\n",
      "[[169  71  52]\n",
      " [ 90 251  46]\n",
      " [ 64  89   0]]\n",
      "[class 0] precision: 0.5788  recall: 0.5232 \n",
      "[class 1] precision: 0.6486  recall: 0.6107 \n",
      "\n",
      "\n",
      "v13 x\n",
      "#images in val: 704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating dual-path: 100%|██████████| 704/704 [00:25<00:00, 27.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AP@50:95: 0.5607\n",
      "[IoU=0.5] AP = 0.8774\n",
      "[IoU=0.5] best F1 = 0.8239\n",
      "[IoU=0.5] best threshold = 0.4539\n",
      "[IoU=0.5] precision = 0.8973, recall = 0.7616\n",
      "\n",
      "Confusion matrix @50 (rows=pred, cols=gt, last index = background):\n",
      "[[171  74  34]\n",
      " [ 72 242  30]\n",
      " [ 80  95   0]]\n",
      "[class 0] precision: 0.6129  recall: 0.5294 \n",
      "[class 1] precision: 0.7035  recall: 0.5888 \n"
     ]
    }
   ],
   "source": [
    "model_dict = {\n",
    "    'v11': ['n', 's', 'm', 'l', 'x'],\n",
    "    'v12': ['n', 's', 'm', 'l', 'x'],\n",
    "    'v13': ['n', 's', 'l', 'x'],\n",
    "}\n",
    "# detection model (YOLOv13-n)\n",
    "for k in model_dict.keys():\n",
    "    for s in model_dict[k]:\n",
    "        print()\n",
    "        print()\n",
    "        print(k, s)\n",
    "        model_path = f\"/nfs/P111yhchen/code/detection/det_branch/{k}/yolo{k}{s}/weights/best.pt\"\n",
    "        model_det = YOLO(model_path)  # Ultralytics 會自動用 CUDA\n",
    "        # ---------------------- main loop ----------------------\n",
    "        img_exts = (\"*.jpg\", \"*.jpeg\", \"*.png\", \"*.bmp\", \"*.tif\")\n",
    "        img_paths = []\n",
    "        for e in img_exts:\n",
    "            img_paths.extend(glob.glob(os.path.join(image_root, e)))\n",
    "        img_paths = sorted(img_paths)\n",
    "\n",
    "        print(f\"#images in val: {len(img_paths)}\")\n",
    "\n",
    "        all_predictions = []  # 全部 pred bbox\n",
    "        gt_boxes_per_image = {}  # img_id -> {cls: [[x1,y1,x2,y2], ...]}\n",
    "\n",
    "        for img_path in tqdm(img_paths, desc=\"Evaluating dual-path\"):\n",
    "            img_id = os.path.splitext(os.path.basename(img_path))[0]\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is None:\n",
    "                continue\n",
    "            h0, w0 = img.shape[:2]\n",
    "\n",
    "            # ------ GT ------\n",
    "            label_path = os.path.join(label_root, img_id + \".txt\")\n",
    "            gt_boxes_per_image[img_id] = load_yolo_gt(label_path, w0, h0)\n",
    "\n",
    "            # ------ detection (YOLO) ------\n",
    "            # Ultralytics: conf threshold 在這裡設定\n",
    "            results = model_det.predict(\n",
    "                img,  # BGR numpy\n",
    "                single_cls=True,\n",
    "                conf=CONF_THRESH_DET,\n",
    "                verbose=False,\n",
    "                iou=0.7,     # NMS 的 IoU 門檻，依需要調\n",
    "                device=device,\n",
    "            )\n",
    "            \n",
    "            r = results[0]\n",
    "            if r.boxes is None or len(r.boxes) == 0:\n",
    "                continue\n",
    "\n",
    "            boxes = r.boxes.xyxy.cpu().numpy()\n",
    "            scores = r.boxes.conf.cpu().numpy()\n",
    "            classes = r.boxes.cls.cpu().numpy()\n",
    "\n",
    "            for box, score, cc in zip(boxes, scores, classes):\n",
    "                all_predictions.append({\n",
    "                    \"image_id\": img_id,\n",
    "                    \"cls\": int(cc),\n",
    "                    \"score\": float(score),\n",
    "                    \"box\": box.tolist(),\n",
    "                })\n",
    "                \n",
    "        # -------------------------------------------------\n",
    "        # 實際計算 AP@50, AP@75, AP@50:95\n",
    "        # all_predictions / gt_boxes_per_image 用你 main loop 算好的那兩個變數\n",
    "        # -------------------------------------------------\n",
    "        # AP@50:95\n",
    "        aps = []\n",
    "        thrs = [] # conf_thr with best F1 score\n",
    "        rs = [] \n",
    "        ps = []\n",
    "        for thr in np.arange(0.5, 1.0, 0.05):  # 0.50, 0.55, ..., 0.95\n",
    "            ap_i, r_i, p_i, _, _, thr_i = compute_ap_class_agnostic(\n",
    "                all_predictions, gt_boxes_per_image, iou_thr=thr\n",
    "            )\n",
    "            aps.append(ap_i)\n",
    "            thrs.append(thr_i)\n",
    "            rs.append(r_i)\n",
    "            ps.append(p_i)\n",
    "        ap_50_95 = float(np.mean(aps))\n",
    "\n",
    "        \n",
    "        best_thr_50, best_f1_50, best_p_50, best_r_50 = find_best_f1_threshold(ps[0], rs[0], thrs[0])\n",
    "\n",
    "        cm = compute_confusion_matrix(\n",
    "            all_predictions,\n",
    "            gt_boxes_per_image,\n",
    "            num_classes=NUM_CLASSES_DET,\n",
    "            conf_th=best_thr_50,   # 想和 ultralytics 一樣就設 0.25\n",
    "            iou_th=0.5\n",
    "        )\n",
    "\n",
    "        print(f\"AP@50:95: {ap_50_95:.4f}\")\n",
    "\n",
    "        print(f\"[IoU=0.5] AP = {aps[0]:.4f}\")\n",
    "        print(f\"[IoU=0.5] best F1 = {best_f1_50:.4f}\")\n",
    "        print(f\"[IoU=0.5] best threshold = {best_thr_50:.4f}\")\n",
    "        print(f\"[IoU=0.5] precision = {best_p_50:.4f}, recall = {best_r_50:.4f}\")\n",
    "\n",
    "        print(\"\\nConfusion matrix @50 (rows=pred, cols=gt, last index = background):\")\n",
    "        print(cm)\n",
    "        for ci in range(NUM_CLASSES_DET):\n",
    "            pp = cm[ci, ci]/cm[ci].sum()\n",
    "            rr = cm[ci, ci]/cm[:, ci].sum()\n",
    "            print(f\"[class {ci}] precision: {pp:.4f}  recall: {rr:.4f} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
